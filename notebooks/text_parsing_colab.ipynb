{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Парсинг текстов с сайтов и соцсетей\n\nЭтот блокнот загружает скрипты из репозитория и помогает быстро получить тексты из:\n- статей и страниц сайтов (универсальный парсер)\n- отзывов Яндекса\n- групп ВК\n\nНиже — установка зависимостей, импорт функций и интерактивные формы для ввода URL/токенов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Установка зависимостей\n",
    "!pip -q install requests beautifulsoup4 lxml ipywidgets pandas shapely pymorphy3 flair folium tqdm osmnx bertopic sentence-transformers plotly hdbscan\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Укажите репозиторий в формате \"owner/repo\" при необходимости\n",
    "REPO_SLUG = os.environ.get(\"GITHUB_REPO\", \"Sandrro/digital_identity\")\n",
    "REPO_URL = f\"https://github.com/{REPO_SLUG}\"\n",
    "REPO_DIR = Path(\"/content/digital_identity\")\n",
    "\n",
    "if not REPO_DIR.exists():\n",
    "    !git clone --depth 1 {REPO_URL} {REPO_DIR}\n",
    "\n",
    "sys.path.insert(0, str(REPO_DIR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Импорт парсеров\n",
    "import sys\n",
    "sys.path.insert(0, \"/content/digital_identity/parsers\")\n",
    "from vk_group_parser import VKGroupParser\n",
    "from website_parser import parse_websites\n",
    "from yandex_reviews_parser import fetch_yandex_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Интерактивный запуск\n",
    "import csv\n",
    "from datetime import date, datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "OUTPUT_CSV = Path(\"/content/digital_identity/parsed_texts.csv\")\n",
    "\n",
    "parser_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        (\"Сайты\", \"website\"),\n",
    "        (\"Яндекс отзывы\", \"yandex\"),\n",
    "        (\"ВК группа\", \"vk\"),\n",
    "    ],\n",
    "    description=\"Парсер:\"\n",
    ")\n",
    "url_input = widgets.Text(\n",
    "    value=\"\",\n",
    "    description=\"URL/домен:\",\n",
    "    placeholder=\"https://...\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "token_input = widgets.Password(\n",
    "    value=\"\",\n",
    "    description=\"VK токен:\",\n",
    "    placeholder=\"Требуется только для ВК\",\n",
    ")\n",
    "max_items = widgets.IntSlider(\n",
    "    value=20,\n",
    "    min=1,\n",
    "    max=200,\n",
    "    step=1,\n",
    "    description=\"Лимит:\"\n",
    ")\n",
    "run_button = widgets.Button(description=\"Запустить\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def _normalize_date(value):\n",
    "    if value in (None, \"\"):\n",
    "        return None\n",
    "    if isinstance(value, datetime):\n",
    "        return value.date().isoformat()\n",
    "    if isinstance(value, date):\n",
    "        return value.isoformat()\n",
    "    parsed = pd.to_datetime(value, errors=\"coerce\", utc=True)\n",
    "    if pd.isna(parsed):\n",
    "        return str(value)[:10]\n",
    "    return parsed.date().isoformat()\n",
    "\n",
    "def _format_vk_timestamp(ts):\n",
    "    if ts is None:\n",
    "        return None\n",
    "    return datetime.fromtimestamp(ts, tz=timezone.utc).date().isoformat()\n",
    "\n",
    "def _write_rows(rows):\n",
    "    if not rows:\n",
    "        return\n",
    "    OUTPUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with OUTPUT_CSV.open(\"w\", newline=\"\", encoding=\"utf-8\") as handle:\n",
    "        writer = csv.DictWriter(\n",
    "            handle,\n",
    "            fieldnames=[\"source\", \"url\", \"title\", \"timestamp\", \"text\"],\n",
    "        )\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "\n",
    "def run_parser(_):\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        rows = []\n",
    "        parser = parser_dropdown.value\n",
    "        if parser == \"website\":\n",
    "            df = parse_websites([url_input.value])\n",
    "            for _, row in df.iterrows():\n",
    "                meta = row.get(\"meta\") or {}\n",
    "                rows.append({\n",
    "                    \"source\": row.get(\"source\"),\n",
    "                    \"url\": row.get(\"url\"),\n",
    "                    \"title\": meta.get(\"title\"),\n",
    "                    \"timestamp\": _normalize_date(row.get(\"date\")),\n",
    "                    \"text\": row.get(\"text_clean\") or row.get(\"text_raw\"),\n",
    "                })\n",
    "        elif parser == \"yandex\":\n",
    "            reviews = fetch_yandex_reviews(url_input.value, max_reviews=max_items.value)\n",
    "            for review in reviews:\n",
    "                rows.append({\n",
    "                    \"source\": \"yandex\",\n",
    "                    \"url\": url_input.value,\n",
    "                    \"title\": None,\n",
    "                    \"timestamp\": None,\n",
    "                    \"text\": review.text,\n",
    "                })\n",
    "        else:\n",
    "            if not token_input.value:\n",
    "                raise ValueError(\"Нужен VK токен.\")\n",
    "            vk = VKGroupParser(token_input.value)\n",
    "            for post in vk.iter_posts(url_input.value, total=max_items.value):\n",
    "                rows.append({\n",
    "                    \"source\": \"vk\",\n",
    "                    \"url\": url_input.value,\n",
    "                    \"title\": None,\n",
    "                    \"timestamp\": _format_vk_timestamp(post.date),\n",
    "                    \"text\": post.text,\n",
    "                })\n",
    "        _write_rows(rows)\n",
    "        if rows:\n",
    "            display(pd.DataFrame(rows))\n",
    "\n",
    "run_button.on_click(run_parser)\n",
    "display(parser_dropdown, url_input, token_input, max_items, run_button, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Геокодирование и визуализация адресов\n\n",
    "Ниже добавлен импорт скрипта геокодера и UI для запуска.\n",
    "В качестве входа используется файл, сохранённый в предыдущей ячейке\n",
    "(`parsed_texts.csv`). Скрипт извлекает топонимы, геокодирует их через Photon,\n",
    "сохраняет результаты в GeoJSON и строит интерактивную карту.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#@title Геокодер: импорт и запуск с UI\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/content/digital_identity/parsers\")\n",
    "from geocoder import geocode_texts, build_geojson, save_geojson, bbox_from_area_name\n",
    "\n",
    "DEFAULT_INPUT = Path(\"/content/digital_identity/parsed_texts.csv\")\n",
    "UPLOAD_TARGET = Path(\"/content/digital_identity/uploaded_texts\")\n",
    "\n",
    "file_picker = widgets.Text(\n",
    "    value=str(DEFAULT_INPUT),\n",
    "    description=\"CSV/текст:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "upload_widget = widgets.FileUpload(accept=\".csv,.txt\", multiple=False)\n",
    "upload_button = widgets.Button(description=\"Загрузить файл\")\n",
    "upload_status = widgets.Label()\n",
    "\n",
    "bbox_input = widgets.Text(\n",
    "    value=\"\",\n",
    "    description=\"BBox:\",\n",
    "    placeholder=\"minx,miny,maxx,maxy (необязательно)\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "bbox_name_input = widgets.Text(\n",
    "    value=\"\",\n",
    "    description=\"Территория:\",\n",
    "    placeholder=\"Например, Москва\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "bbox_resolve = widgets.Button(description=\"Определить BBox\")\n",
    "bbox_status = widgets.Label()\n",
    "\n",
    "geojson_output = widgets.Text(\n",
    "    value=\"/content/digital_identity/geocoded_points.geojson\",\n",
    "    description=\"GeoJSON:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "run_geocoder = widgets.Button(description=\"Геокодировать\")\n",
    "geo_output = widgets.Output()\n",
    "\n",
    "\n",
    "def _load_texts(path: Path) -> list[str]:\n",
    "    if path.suffix.lower() == \".txt\":\n",
    "        return [line.rstrip() for line in path.read_text(encoding=\"utf-8\").splitlines()]\n",
    "    df = pd.read_csv(path)\n",
    "    if \"text\" not in df.columns:\n",
    "        raise ValueError(\"CSV должен содержать колонку text\")\n",
    "    return df[\"text\"].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "\n",
    "def _extract_upload_payload():\n",
    "    upload_value = upload_widget.value\n",
    "    if isinstance(upload_value, dict):\n",
    "        if not upload_value:\n",
    "            return None, None\n",
    "        return next(iter(upload_value.items()))\n",
    "    if isinstance(upload_value, (list, tuple)):\n",
    "        if not upload_value:\n",
    "            return None, None\n",
    "        payload = upload_value[0]\n",
    "        name = payload.get(\"name\") or payload.get(\"metadata\", {}).get(\"name\")\n",
    "        return name, payload\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def _handle_upload(_):\n",
    "    upload_status.value = \"\"\n",
    "    name, payload = _extract_upload_payload()\n",
    "    if not name or not payload:\n",
    "        upload_status.value = \"Выберите файл для загрузки\"\n",
    "        return\n",
    "    suffix = Path(name).suffix or \".txt\"\n",
    "    target = UPLOAD_TARGET.with_suffix(suffix)\n",
    "    target.write_bytes(payload[\"content\"])\n",
    "    file_picker.value = str(target)\n",
    "    upload_status.value = f\"Файл сохранен: {target}\"\n",
    "\n",
    "\n",
    "def _resolve_bbox(_):\n",
    "    bbox_status.value = \"\"\n",
    "    name = bbox_name_input.value.strip()\n",
    "    if not name:\n",
    "        bbox_status.value = \"Введите название территории\"\n",
    "        return\n",
    "    try:\n",
    "        bbox_value = bbox_from_area_name(name)\n",
    "    except Exception as exc:\n",
    "        bbox_status.value = f\"Ошибка: {exc}\"\n",
    "        return\n",
    "    bbox_input.value = bbox_value\n",
    "    bbox_status.value = \"BBox обновлен\"\n",
    "\n",
    "\n",
    "def _results_to_gdf(results: list) -> gpd.GeoDataFrame:\n",
    "    rows = [\n",
    "        {\n",
    "            \"geometry\": res.geometry,\n",
    "            \"location\": res.location,\n",
    "            \"osm_id\": res.osm_id,\n",
    "            \"text\": res.source_text,\n",
    "        }\n",
    "        for res in results\n",
    "        if res.geometry is not None\n",
    "    ]\n",
    "    return gpd.GeoDataFrame(rows, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "\n",
    "def _run_geocoding(_):\n",
    "    geo_output.clear_output()\n",
    "    with geo_output:\n",
    "        csv_path = Path(file_picker.value).expanduser()\n",
    "        if not csv_path.exists():\n",
    "            raise FileNotFoundError(f\"Файл не найден: {csv_path}\")\n",
    "        texts = _load_texts(csv_path)\n",
    "        bbox = bbox_input.value.strip() or None\n",
    "        bbox_name = bbox_name_input.value.strip() or None\n",
    "        results = geocode_texts(texts, bbox=bbox, bbox_name=bbox_name)\n",
    "        geojson_data = build_geojson(results)\n",
    "        save_geojson(geojson_output.value, geojson_data)\n",
    "        display({\"geojson\": geojson_output.value})\n",
    "        gdf = _results_to_gdf(results)\n",
    "        if gdf.empty:\n",
    "            display(\"Нет точек для отображения на карте.\")\n",
    "        else:\n",
    "            display(gdf.explore())\n",
    "\n",
    "\n",
    "upload_button.on_click(_handle_upload)\n",
    "bbox_resolve.on_click(_resolve_bbox)\n",
    "run_geocoder.on_click(_run_geocoding)\n",
    "\n",
    "display(\n",
    "    file_picker,\n",
    "    widgets.HBox([upload_widget, upload_button]),\n",
    "    upload_status,\n",
    "    bbox_input,\n",
    "    widgets.HBox([bbox_name_input, bbox_resolve]),\n",
    "    bbox_status,\n",
    "    geojson_output,\n",
    "    run_geocoder,\n",
    "    geo_output,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Классификатор эмоций: импорт и запуск с UI\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/content/digital_identity/parsers\")\n",
    "from emotion_classifier import models_initialization, classify_emotions\n",
    "\n",
    "DEFAULT_INPUT = Path(\"/content/digital_identity/parsed_texts.csv\")\n",
    "UPLOAD_TARGET = Path(\"/content/digital_identity/uploaded_texts\")\n",
    "\n",
    "file_picker = widgets.Text(\n",
    "    value=str(DEFAULT_INPUT),\n",
    "    description=\"CSV/GeoJSON:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "upload_widget = widgets.FileUpload(accept=\".csv,.geojson,.json\", multiple=False)\n",
    "upload_button = widgets.Button(description=\"Загрузить файл\")\n",
    "upload_status = widgets.Label()\n",
    "\n",
    "output_path = widgets.Text(\n",
    "    value=\"/content/digital_identity/emotions_output.csv\",\n",
    "    description=\"Выход:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "run_classifier = widgets.Button(description=\"Классифицировать\")\n",
    "classifier_output = widgets.Output()\n",
    "\n",
    "\n",
    "def _default_output_path(input_path: Path) -> Path:\n",
    "    suffix = input_path.suffix.lower()\n",
    "    if suffix in {\".geojson\", \".json\"}:\n",
    "        return input_path.with_name(f\"{input_path.stem}_emotions.geojson\")\n",
    "    return input_path.with_name(f\"{input_path.stem}_emotions.csv\")\n",
    "\n",
    "\n",
    "def _ensure_output_path(raw_value: str, input_path: Path) -> Path:\n",
    "    target = Path(raw_value) if raw_value else _default_output_path(input_path)\n",
    "    suffix = \".geojson\" if input_path.suffix.lower() in {\".geojson\", \".json\"} else \".csv\"\n",
    "    if target.suffix.lower() != suffix:\n",
    "        target = target.with_suffix(suffix)\n",
    "    return target\n",
    "\n",
    "\n",
    "def _load_dataset(path: Path):\n",
    "    suffix = path.suffix.lower()\n",
    "    if suffix in {\".geojson\", \".json\"}:\n",
    "        gdf = gpd.read_file(path)\n",
    "        if \"text\" not in gdf.columns:\n",
    "            raise ValueError(\"GeoJSON должен содержать колонку text\")\n",
    "        return gdf, \"geojson\"\n",
    "    if suffix == \".csv\":\n",
    "        df = pd.read_csv(path)\n",
    "        if \"text\" not in df.columns:\n",
    "            raise ValueError(\"CSV должен содержать колонку text\")\n",
    "        return df, \"csv\"\n",
    "    raise ValueError(\"Поддерживаются только CSV или GeoJSON файлы\")\n",
    "\n",
    "\n",
    "def _extract_upload_payload():\n",
    "    upload_value = upload_widget.value\n",
    "    if isinstance(upload_value, dict):\n",
    "        if not upload_value:\n",
    "            return None, None\n",
    "        return next(iter(upload_value.items()))\n",
    "    if isinstance(upload_value, (list, tuple)):\n",
    "        if not upload_value:\n",
    "            return None, None\n",
    "        payload = upload_value[0]\n",
    "        name = payload.get(\"name\") or payload.get(\"metadata\", {}).get(\"name\")\n",
    "        return name, payload\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def _handle_upload(_):\n",
    "    upload_status.value = \"\"\n",
    "    name, payload = _extract_upload_payload()\n",
    "    if not name or not payload:\n",
    "        upload_status.value = \"Выберите файл для загрузки\"\n",
    "        return\n",
    "    suffix = Path(name).suffix or \".csv\"\n",
    "    target = UPLOAD_TARGET.with_suffix(suffix)\n",
    "    target.write_bytes(payload[\"content\"])\n",
    "    file_picker.value = str(target)\n",
    "    upload_status.value = f\"Файл сохранен: {target}\"\n",
    "\n",
    "\n",
    "def _plot_emotions(df: pd.DataFrame) -> None:\n",
    "    counts = df[\"emotion\"].value_counts()\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.pie(counts.values, labels=counts.index, autopct=\"%1.1f%%\")\n",
    "    ax.set_title(\"Распределение эмоций\")\n",
    "    display(fig)\n",
    "\n",
    "\n",
    "def _run_classification(_):\n",
    "    classifier_output.clear_output()\n",
    "    with classifier_output:\n",
    "        input_path = Path(file_picker.value).expanduser()\n",
    "        if not input_path.exists():\n",
    "            raise FileNotFoundError(f\"Файл не найден: {input_path}\")\n",
    "        data, data_type = _load_dataset(input_path)\n",
    "        if models_initialization._classification_model is None:\n",
    "            models_initialization.init_models()\n",
    "        texts = data[\"text\"].fillna(\"\").astype(str).tolist()\n",
    "        data[\"emotion\"] = classify_emotions(texts)\n",
    "        target = _ensure_output_path(output_path.value, input_path)\n",
    "        output_path.value = str(target)\n",
    "        if data_type == \"geojson\":\n",
    "            data.to_file(target, driver=\"GeoJSON\")\n",
    "        else:\n",
    "            data.to_csv(target, index=False)\n",
    "        display({\"output\": str(target)})\n",
    "        display(data.head())\n",
    "        _plot_emotions(data)\n",
    "\n",
    "\n",
    "upload_button.on_click(_handle_upload)\n",
    "run_classifier.on_click(_run_classification)\n",
    "\n",
    "display(\n",
    "    file_picker,\n",
    "    widgets.HBox([upload_widget, upload_button]),\n",
    "    upload_status,\n",
    "    output_path,\n",
    "    run_classifier,\n",
    "    classifier_output,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тематическое моделирование (BERTopic)\n",
    "\n",
    "Модуль принимает CSV/GeoJSON с колонкой `text`, кластеризует тексты с помощью BERTopic, ",
    "добавляет номер и ключевые слова темы, а также строит визуализации результатов. ",
    "Если указана колонка времени, дополнительно появляется динамика тем.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title BERTopic: кластеризация тем и визуализация\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "from IPython.display import display\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/content/digital_identity\")\n",
    "from parsers.topic_modeler import attach_topics, train_topic_model\n",
    "\n",
    "pio.renderers.default = \"colab\"\n",
    "\n",
    "DEFAULT_INPUT = Path(\"/content/digital_identity/parsed_texts.csv\")\n",
    "UPLOAD_TARGET = Path(\"/content/digital_identity/uploaded_topics\")\n",
    "\n",
    "file_picker = widgets.Text(\n",
    "    value=str(DEFAULT_INPUT),\n",
    "    description=\"CSV/GeoJSON:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "upload_widget = widgets.FileUpload(accept=\".csv,.geojson,.json\", multiple=False)\n",
    "upload_button = widgets.Button(description=\"Загрузить файл\")\n",
    "upload_status = widgets.Label()\n",
    "\n",
    "text_column = widgets.Text(\n",
    "    value=\"text\",\n",
    "    description=\"Колонка текста:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "timestamp_column = widgets.Text(\n",
    "    value=\"\",\n",
    "    description=\"Колонка времени:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "\n",
    "language_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        (\"Многоязычный\", \"multilingual\"),\n",
    "        (\"Русский\", \"russian\"),\n",
    "        (\"English\", \"english\"),\n",
    "    ],\n",
    "    value=\"multilingual\",\n",
    "    description=\"Язык:\",\n",
    ")\n",
    "embedding_model = widgets.Text(\n",
    "    value=\"\",\n",
    "    description=\"Embedding модель:\",\n",
    "    placeholder=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "\n",
    "cluster_method = widgets.ToggleButtons(\n",
    "    options=[(\"HDBSCAN\", \"hdbscan\"), (\"k-means\", \"kmeans\")],\n",
    "    value=\"hdbscan\",\n",
    "    description=\"Кластеризация:\",\n",
    ")\n",
    "min_topic_size = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=2,\n",
    "    max=50,\n",
    "    step=1,\n",
    "    description=\"Мин. размер темы:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "min_samples = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=1,\n",
    "    max=50,\n",
    "    step=1,\n",
    "    description=\"min_samples:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "n_clusters = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=2,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description=\"k-means k:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "\n",
    "nr_topics = widgets.IntText(\n",
    "    value=0,\n",
    "    description=\"Число тем (0=auto):\",\n",
    ")\n",
    "top_n_keywords = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=3,\n",
    "    max=15,\n",
    "    step=1,\n",
    "    description=\"Ключевые слова:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "reduce_frequent_words = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description=\"Фильтровать частотные слова (TF-IDF)\",\n",
    ")\n",
    "\n",
    "output_path = widgets.Text(\n",
    "    value=\"/content/digital_identity/topics_output.csv\",\n",
    "    description=\"Выход:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "\n",
    "visualizations = widgets.SelectMultiple(\n",
    "    options=[\n",
    "        (\"Карта тем\", \"topics\"),\n",
    "        (\"Бархарт\", \"barchart\"),\n",
    "        (\"Иерархия\", \"hierarchy\"),\n",
    "        (\"Тепловая карта\", \"heatmap\"),\n",
    "        (\"Темы во времени\", \"over_time\"),\n",
    "    ],\n",
    "    value=(\"topics\", \"barchart\"),\n",
    "    description=\"Визуализации:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "\n",
    "run_model = widgets.Button(description=\"Построить темы\")\n",
    "model_output = widgets.Output()\n",
    "\n",
    "\n",
    "def _default_output_path(input_path: Path) -> Path:\n",
    "    suffix = input_path.suffix.lower()\n",
    "    if suffix in {\".geojson\", \".json\"}:\n",
    "        return input_path.with_name(f\"{input_path.stem}_topics.geojson\")\n",
    "    return input_path.with_name(f\"{input_path.stem}_topics.csv\")\n",
    "\n",
    "\n",
    "def _ensure_output_path(raw_value: str, input_path: Path) -> Path:\n",
    "    target = Path(raw_value) if raw_value else _default_output_path(input_path)\n",
    "    suffix = \".geojson\" if input_path.suffix.lower() in {\".geojson\", \".json\"} else \".csv\"\n",
    "    if target.suffix.lower() != suffix:\n",
    "        target = target.with_suffix(suffix)\n",
    "    return target\n",
    "\n",
    "\n",
    "def _load_dataset(path: Path):\n",
    "    suffix = path.suffix.lower()\n",
    "    if suffix in {\".geojson\", \".json\"}:\n",
    "        gdf = gpd.read_file(path)\n",
    "        return gdf, \"geojson\"\n",
    "    if suffix == \".csv\":\n",
    "        df = pd.read_csv(path)\n",
    "        return df, \"csv\"\n",
    "    raise ValueError(\"Поддерживаются только CSV или GeoJSON файлы\")\n",
    "\n",
    "\n",
    "def _extract_upload_payload():\n",
    "    upload_value = upload_widget.value\n",
    "    if isinstance(upload_value, dict):\n",
    "        if not upload_value:\n",
    "            return None, None\n",
    "        return next(iter(upload_value.items()))\n",
    "    if isinstance(upload_value, (list, tuple)):\n",
    "        if not upload_value:\n",
    "            return None, None\n",
    "        payload = upload_value[0]\n",
    "        name = payload.get(\"name\") or payload.get(\"metadata\", {}).get(\"name\")\n",
    "        return name, payload\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def _handle_upload(_):\n",
    "    upload_status.value = \"\"\n",
    "    name, payload = _extract_upload_payload()\n",
    "    if not name or not payload:\n",
    "        upload_status.value = \"Выберите файл для загрузки\"\n",
    "        return\n",
    "    suffix = Path(name).suffix or \".csv\"\n",
    "    target = UPLOAD_TARGET.with_suffix(suffix)\n",
    "    target.write_bytes(payload[\"content\"])\n",
    "    file_picker.value = str(target)\n",
    "    upload_status.value = f\"Файл сохранен: {target}\"\n",
    "\n",
    "\n",
    "def _parse_timestamps(data: pd.DataFrame, column_name: str):\n",
    "    if not column_name:\n",
    "        return None\n",
    "    if column_name not in data.columns:\n",
    "        raise ValueError(f\"Колонка времени '{column_name}' не найдена\")\n",
    "    timestamps = pd.to_datetime(data[column_name], errors=\"coerce\")\n",
    "    if timestamps.isna().all():\n",
    "        raise ValueError(\"Не удалось распознать временные метки\")\n",
    "    return timestamps\n",
    "\n",
    "\n",
    "def _run_topic_model(_):\n",
    "    model_output.clear_output()\n",
    "    with model_output:\n",
    "        input_path = Path(file_picker.value).expanduser()\n",
    "        if not input_path.exists():\n",
    "            raise FileNotFoundError(f\"Файл не найден: {input_path}\")\n",
    "        data, data_type = _load_dataset(input_path)\n",
    "        text_col = text_column.value.strip() or \"text\"\n",
    "        if text_col not in data.columns:\n",
    "            raise ValueError(f\"Колонка текста '{text_col}' не найдена\")\n",
    "        texts = data[text_col].fillna(\"\").astype(str).tolist()\n",
    "        timestamps = _parse_timestamps(data, timestamp_column.value.strip())\n",
    "\n",
    "        result = train_topic_model(\n",
    "            texts,\n",
    "            language=language_dropdown.value,\n",
    "            min_topic_size=min_topic_size.value,\n",
    "            nr_topics=nr_topics.value or None,\n",
    "            embedding_model=embedding_model.value.strip() or None,\n",
    "            cluster_method=cluster_method.value,\n",
    "            n_clusters=n_clusters.value if cluster_method.value == \"kmeans\" else None,\n",
    "            min_samples=min_samples.value if cluster_method.value == \"hdbscan\" else None,\n",
    "            reduce_frequent_words=reduce_frequent_words.value,\n",
    "        )\n",
    "        data = attach_topics(\n",
    "            data,\n",
    "            result.topics,\n",
    "            result.model,\n",
    "            top_n=top_n_keywords.value,\n",
    "        )\n",
    "\n",
    "        target = _ensure_output_path(output_path.value, input_path)\n",
    "        output_path.value = str(target)\n",
    "        if data_type == \"geojson\":\n",
    "            data.to_file(target, driver=\"GeoJSON\")\n",
    "        else:\n",
    "            data.to_csv(target, index=False)\n",
    "\n",
    "        display({\"output\": str(target)})\n",
    "        display(data.head())\n",
    "        topic_info = result.model.get_topic_info()\n",
    "        display(topic_info.head(10))\n",
    "\n",
    "        available_topics = topic_info[topic_info[\"Topic\"] != -1]\n",
    "        topic_count = len(available_topics)\n",
    "\n",
    "        selected = set(visualizations.value)\n",
    "        if \"topics\" in selected:\n",
    "            display(result.model.visualize_topics())\n",
    "        if \"barchart\" in selected:\n",
    "            display(result.model.visualize_barchart(top_n_topics=20))\n",
    "        if \"hierarchy\" in selected:\n",
    "            if topic_count < 2:\n",
    "                display(\"Недостаточно тем для иерархии (нужно минимум 2).\")\n",
    "            else:\n",
    "                display(result.model.visualize_hierarchy())\n",
    "        if \"heatmap\" in selected:\n",
    "            if topic_count < 2:\n",
    "                display(\"Недостаточно тем для тепловой карты (нужно минимум 2).\")\n",
    "            else:\n",
    "                display(result.model.visualize_heatmap())\n",
    "        if \"over_time\" in selected:\n",
    "            if timestamps is None:\n",
    "                display(\"Для динамики тем укажите колонку времени.\")\n",
    "            else:\n",
    "                topics_over_time = result.model.topics_over_time(\n",
    "                    texts, timestamps, nr_bins=20\n",
    "                )\n",
    "                display(result.model.visualize_topics_over_time(topics_over_time))\n",
    "\n",
    "\n",
    "def _toggle_cluster_controls(change=None):\n",
    "    is_kmeans = cluster_method.value == \"kmeans\"\n",
    "    n_clusters.layout.display = \"\" if is_kmeans else \"none\"\n",
    "    min_samples.layout.display = \"none\" if is_kmeans else \"\"\n",
    "\n",
    "\n",
    "cluster_method.observe(_toggle_cluster_controls, names=\"value\")\n",
    "_toggle_cluster_controls()\n",
    "\n",
    "upload_button.on_click(_handle_upload)\n",
    "run_model.on_click(_run_topic_model)\n",
    "\n",
    "display(\n",
    "    file_picker,\n",
    "    widgets.HBox([upload_widget, upload_button]),\n",
    "    upload_status,\n",
    "    text_column,\n",
    "    timestamp_column,\n",
    "    language_dropdown,\n",
    "    embedding_model,\n",
    "    cluster_method,\n",
    "    min_topic_size,\n",
    "    min_samples,\n",
    "    n_clusters,\n",
    "    nr_topics,\n",
    "    top_n_keywords,\n",
    "    reduce_frequent_words,\n",
    "    output_path,\n",
    "    visualizations,\n",
    "    run_model,\n",
    "    model_output,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "text_parsing_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}