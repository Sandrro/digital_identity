{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инструменты сбора данных\n",
    "\n",
    "## Парсинг текстов с сайтов и соцсетей\n",
    "\n",
    "Этот раздел помогает собрать тексты из сайтов, Яндекс‑отзывов и групп ВК и сохранить их в CSV.\n",
    "\n",
    "**Как пользоваться:**\n",
    "1. Запустите ячейки **«Установка зависимостей»** и **«Импорт парсеров»**.\n",
    "2. В выпадающем списке выберите источник (сайты / Яндекс отзывы / ВК).\n",
    "3. Укажите URL или домен. Для ВК дополнительно вставьте токен доступа.\n",
    "4. Задайте лимит записей и нажмите **«Запустить»**.\n",
    "5. Результаты сохраняются в `parsed_texts.csv` и выводятся в таблице.\n",
    "\n",
    "Поддерживаемые форматы: CSV с колонкой `text` используется далее во всех инструментах анализа.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Установка зависимостей\n",
    "!pip -q install requests beautifulsoup4 lxml ipywidgets pandas shapely pymorphy3 flair folium tqdm osmnx bertopic sentence-transformers plotly hdbscan wordcloud keybert kaleido\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Укажите репозиторий в формате \"owner/repo\" при необходимости\n",
    "REPO_SLUG = os.environ.get(\"GITHUB_REPO\", \"Sandrro/digital_identity\")\n",
    "REPO_URL = f\"https://github.com/{REPO_SLUG}\"\n",
    "REPO_DIR = Path(\"/content/digital_identity\")\n",
    "\n",
    "if not REPO_DIR.exists():\n",
    "    !git clone --depth 1 {REPO_URL} {REPO_DIR}\n",
    "\n",
    "sys.path.insert(0, str(REPO_DIR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Импорт парсеров\n",
    "import sys\n",
    "sys.path.insert(0, \"/content/digital_identity/parsers\")\n",
    "from vk_group_parser import VKGroupParser\n",
    "from website_parser import parse_websites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Интерактивный запуск\n",
    "import csv\n",
    "from datetime import date, datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "OUTPUT_CSV = Path(\"/content/digital_identity/parsed_texts.csv\")\n",
    "LINKS_UPLOAD_TARGET = Path(\"/content/digital_identity/uploaded_links.csv\")\n",
    "\n",
    "parser_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        (\"Сайты\", \"website\"),\n",
    "        (\"ВК группа\", \"vk\"),\n",
    "    ],\n",
    "    description=\"Парсер:\"\n",
    ")\n",
    "url_input = widgets.Text(\n",
    "    value=\"\",\n",
    "    description=\"URL/домен:\",\n",
    "    placeholder=\"https://...\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "links_input = widgets.Textarea(\n",
    "    value=\"\",\n",
    "    description=\"Ссылки:\",\n",
    "    placeholder=\"https://site1\\nhttps://site2\",\n",
    "    layout=widgets.Layout(width=\"80%\", height=\"120px\"),\n",
    ")\n",
    "links_upload = widgets.FileUpload(accept=\".csv\", multiple=False)\n",
    "links_upload_button = widgets.Button(description=\"Загрузить список\")\n",
    "links_upload_status = widgets.Label()\n",
    "links_upload_path = {\"path\": None}\n",
    "\n",
    "token_input = widgets.Password(\n",
    "    value=\"\",\n",
    "    description=\"VK токен:\",\n",
    "    placeholder=\"Требуется только для ВК\",\n",
    ")\n",
    "max_items = widgets.IntSlider(\n",
    "    value=20,\n",
    "    min=1,\n",
    "    max=200,\n",
    "    step=1,\n",
    "    description=\"Лимит:\"\n",
    ")\n",
    "run_button = widgets.Button(description=\"Запустить\")\n",
    "progress = widgets.IntProgress(value=0, min=0, max=1, description=\"Прогресс:\")\n",
    "progress_label = widgets.Label()\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "def _normalize_date(value):\n",
    "    if value in (None, \"\"):\n",
    "        return None\n",
    "    if isinstance(value, datetime):\n",
    "        return value.date().isoformat()\n",
    "    if isinstance(value, date):\n",
    "        return value.isoformat()\n",
    "    parsed = pd.to_datetime(value, errors=\"coerce\", utc=True)\n",
    "    if pd.isna(parsed):\n",
    "        return str(value)[:10]\n",
    "    return parsed.date().isoformat()\n",
    "\n",
    "\n",
    "def _format_vk_timestamp(ts):\n",
    "    if ts is None:\n",
    "        return None\n",
    "    return datetime.fromtimestamp(ts, tz=timezone.utc).date().isoformat()\n",
    "\n",
    "\n",
    "def _write_rows(rows):\n",
    "    if not rows:\n",
    "        return\n",
    "    OUTPUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with OUTPUT_CSV.open(\"w\", newline=\"\", encoding=\"utf-8\") as handle:\n",
    "        writer = csv.DictWriter(\n",
    "            handle,\n",
    "            fieldnames=[\"source\", \"url\", \"title\", \"timestamp\", \"text\"],\n",
    "        )\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "\n",
    "\n",
    "def _extract_upload_payload(upload_widget):\n",
    "    upload_value = upload_widget.value\n",
    "    if isinstance(upload_value, dict):\n",
    "        if not upload_value:\n",
    "            return None, None\n",
    "        return next(iter(upload_value.items()))\n",
    "    if isinstance(upload_value, (list, tuple)):\n",
    "        if not upload_value:\n",
    "            return None, None\n",
    "        payload = upload_value[0]\n",
    "        name = payload.get(\"name\") or payload.get(\"metadata\", {}).get(\"name\")\n",
    "        return name, payload\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def _handle_links_upload(_):\n",
    "    links_upload_status.value = \"\"\n",
    "    name, payload = _extract_upload_payload(links_upload)\n",
    "    if not name or not payload:\n",
    "        links_upload_status.value = \"Выберите CSV со ссылками\"\n",
    "        return\n",
    "    suffix = Path(name).suffix or \".csv\"\n",
    "    target = LINKS_UPLOAD_TARGET.with_suffix(suffix)\n",
    "    target.write_bytes(payload[\"content\"])\n",
    "    links_upload_path[\"path\"] = target\n",
    "    links_upload_status.value = f\"Файл сохранён: {target}\"\n",
    "\n",
    "\n",
    "def _parse_links_text(raw_value: str) -> list[str]:\n",
    "    if not raw_value:\n",
    "        return []\n",
    "    raw_value = raw_value.replace(\",\", \"\\n\")\n",
    "\")\n",
    "    return [item.strip() for item in raw_value.splitlines() if item.strip()]\n",
    "\n",
    "\n",
    "def _collect_links() -> list[str]:\n",
    "    links: list[str] = []\n",
    "    saved_path = links_upload_path.get(\"path\")\n",
    "    if saved_path and Path(saved_path).exists():\n",
    "        df = pd.read_csv(saved_path)\n",
    "        if \"link\" not in df.columns:\n",
    "            raise ValueError(\"CSV должен содержать колонку 'link'\")\n",
    "        links.extend(df[\"link\"].dropna().astype(str).tolist())\n",
    "    links.extend(_parse_links_text(links_input.value.strip()))\n",
    "    if url_input.value.strip():\n",
    "        links.append(url_input.value.strip())\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for link in links:\n",
    "        if link in seen:\n",
    "            continue\n",
    "        seen.add(link)\n",
    "        result.append(link)\n",
    "    return result\n",
    "\n",
    "\n",
    "def _toggle_parser(change=None):\n",
    "    is_vk = parser_dropdown.value == \"vk\"\n",
    "    token_input.layout.display = \"\" if is_vk else \"none\"\n",
    "    links_input.layout.display = \"none\" if is_vk else \"\"\n",
    "    links_upload.layout.display = \"none\" if is_vk else \"\"\n",
    "    links_upload_button.layout.display = \"none\" if is_vk else \"\"\n",
    "    links_upload_status.layout.display = \"none\" if is_vk else \"\"\n",
    "\n",
    "\n",
    "def run_parser(_):\n",
    "    output.clear_output()\n",
    "    progress.value = 0\n",
    "    progress_label.value = \"\"\n",
    "    with output:\n",
    "        rows = []\n",
    "        parser = parser_dropdown.value\n",
    "        if parser == \"website\":\n",
    "            links = _collect_links()\n",
    "            if not links:\n",
    "                raise ValueError(\"Добавьте хотя бы одну ссылку.\")\n",
    "            progress.max = len(links)\n",
    "            df = parse_websites(links, show_progress=True)\n",
    "            for _, row in df.iterrows():\n",
    "                meta = row.get(\"meta\") or {}\n",
    "                rows.append({\n",
    "                    \"source\": row.get(\"source\"),\n",
    "                    \"url\": row.get(\"url\"),\n",
    "                    \"title\": meta.get(\"title\"),\n",
    "                    \"timestamp\": _normalize_date(row.get(\"date\")),\n",
    "                    \"text\": row.get(\"text_clean\") or row.get(\"text_raw\"),\n",
    "                })\n",
    "            progress.value = len(rows)\n",
    "        else:\n",
    "            if not token_input.value:\n",
    "                raise ValueError(\"Нужен VK токен.\")\n",
    "            progress.max = max_items.value\n",
    "            vk = VKGroupParser(token_input.value)\n",
    "            for idx, post in enumerate(vk.iter_posts(url_input.value, total=max_items.value), start=1):\n",
    "                rows.append({\n",
    "                    \"source\": \"vk\",\n",
    "                    \"url\": url_input.value,\n",
    "                    \"title\": None,\n",
    "                    \"timestamp\": _format_vk_timestamp(post.date),\n",
    "                    \"text\": post.text,\n",
    "                })\n",
    "                progress.value = idx\n",
    "        _write_rows(rows)\n",
    "        progress_label.value = f\"Загружено текстов: {len(rows)}\"\n",
    "        if rows:\n",
    "            display(pd.DataFrame(rows))\n",
    "\n",
    "\n",
    "parser_dropdown.observe(_toggle_parser, names=\"value\")\n",
    "_toggle_parser()\n",
    "links_upload_button.on_click(_handle_links_upload)\n",
    "run_button.on_click(run_parser)\n",
    "\n",
    "display(\n",
    "    parser_dropdown,\n",
    "    url_input,\n",
    "    links_input,\n",
    "    widgets.HBox([links_upload, links_upload_button]),\n",
    "    links_upload_status,\n",
    "    token_input,\n",
    "    max_items,\n",
    "    run_button,\n",
    "    progress,\n",
    "    progress_label,\n",
    "    output,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструменты анализа\n",
    "\n",
    "### Геокодирование и визуализация адресов\n",
    "\n",
    "Инструмент извлекает топонимы из текстов, геокодирует их через Photon и строит интерактивную карту.\n",
    "\n",
    "**Как пользоваться:**\n",
    "1. Укажите путь к CSV/GeoJSON (обычно `parsed_texts.csv`) или загрузите файл.\n",
    "2. При необходимости задайте `BBox` вручную или укажите территорию и нажмите **«Определить BBox»**.\n",
    "3. Укажите путь для GeoJSON‑вывода.\n",
    "4. Нажмите **«Геокодировать»** — на выходе получите GeoJSON и интерактивную карту.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#@title Геокодер: импорт и запуск с UI\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/content/digital_identity/parsers\")\n",
    "from geocoder import geocode_texts, build_geojson, save_geojson, save_map, bbox_from_area_name\n",
    "\n",
    "DEFAULT_INPUT = Path(\"/content/digital_identity/parsed_texts.csv\")\n",
    "UPLOAD_TARGET = Path(\"/content/digital_identity/uploaded_texts\")\n",
    "\n",
    "file_picker = widgets.Text(\n",
    "    value=str(DEFAULT_INPUT),\n",
    "    description=\"CSV/текст:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "upload_widget = widgets.FileUpload(accept=\".csv,.txt\", multiple=False)\n",
    "upload_button = widgets.Button(description=\"Загрузить файл\")\n",
    "upload_status = widgets.Label()\n",
    "\n",
    "bbox_input = widgets.Text(\n",
    "    value=\"\",\n",
    "    description=\"BBox:\",\n",
    "    placeholder=\"minx,miny,maxx,maxy (необязательно)\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "bbox_name_input = widgets.Text(\n",
    "    value=\"\",\n",
    "    description=\"Территория:\",\n",
    "    placeholder=\"Например, Москва\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "bbox_resolve = widgets.Button(description=\"Определить BBox\")\n",
    "bbox_status = widgets.Label()\n",
    "\n",
    "output_path = widgets.Text(\n",
    "    value=\"/content/digital_identity/geocoded_points.geojson\",\n",
    "    description=\"Выход:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "map_output = widgets.Text(\n",
    "    value=\"/content/digital_identity/geocoded_map.html\",\n",
    "    description=\"Карта:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "run_geocoder = widgets.Button(description=\"Геокодировать\")\n",
    "geo_output = widgets.Output()\n",
    "\n",
    "\n",
    "def _default_output_path(input_path: Path) -> Path:\n",
    "    suffix = input_path.suffix.lower()\n",
    "    if suffix == \".csv\":\n",
    "        return input_path.with_name(f\"{input_path.stem}_geocoded.csv\")\n",
    "    return input_path.with_name(f\"{input_path.stem}_geocoded.geojson\")\n",
    "\n",
    "\n",
    "def _ensure_output_path(raw_value: str, input_path: Path) -> Path:\n",
    "    target = Path(raw_value) if raw_value else _default_output_path(input_path)\n",
    "    suffix = \".csv\" if input_path.suffix.lower() == \".csv\" else \".geojson\"\n",
    "    if target.suffix.lower() != suffix:\n",
    "        target = target.with_suffix(suffix)\n",
    "    return target\n",
    "\n",
    "\n",
    "def _load_texts(path: Path):\n",
    "    suffix = path.suffix.lower()\n",
    "    if suffix == \".txt\":\n",
    "        return [line.rstrip() for line in path.read_text(encoding=\"utf-8\").splitlines()], None, \"text\"\n",
    "    if suffix == \".csv\":\n",
    "        df = pd.read_csv(path)\n",
    "        if \"text\" not in df.columns:\n",
    "            raise ValueError(\"CSV должен содержать колонку text\")\n",
    "        return df[\"text\"].fillna(\"\").astype(str).tolist(), df, \"csv\"\n",
    "    if suffix in {\".geojson\", \".json\"}:\n",
    "        gdf = gpd.read_file(path)\n",
    "        if \"text\" not in gdf.columns:\n",
    "            raise ValueError(\"GeoJSON должен содержать колонку text\")\n",
    "        return gdf[\"text\"].fillna(\"\").astype(str).tolist(), gdf, \"geojson\"\n",
    "    raise ValueError(\"Поддерживаются только TXT/CSV/GeoJSON\")\n",
    "\n",
    "\n",
    "def _extract_upload_payload():\n",
    "    upload_value = upload_widget.value\n",
    "    if isinstance(upload_value, dict):\n",
    "        if not upload_value:\n",
    "            return None, None\n",
    "        return next(iter(upload_value.items()))\n",
    "    if isinstance(upload_value, (list, tuple)):\n",
    "        if not upload_value:\n",
    "            return None, None\n",
    "        payload = upload_value[0]\n",
    "        name = payload.get(\"name\") or payload.get(\"metadata\", {}).get(\"name\")\n",
    "        return name, payload\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def _handle_upload(_):\n",
    "    upload_status.value = \"\"\n",
    "    name, payload = _extract_upload_payload()\n",
    "    if not name or not payload:\n",
    "        upload_status.value = \"Выберите файл для загрузки\"\n",
    "        return\n",
    "    suffix = Path(name).suffix or \".txt\"\n",
    "    target = UPLOAD_TARGET.with_suffix(suffix)\n",
    "    target.write_bytes(payload[\"content\"])\n",
    "    file_picker.value = str(target)\n",
    "    upload_status.value = f\"Файл сохранён: {target}\"\n",
    "\n",
    "\n",
    "def _resolve_bbox(_):\n",
    "    bbox_status.value = \"\"\n",
    "    name = bbox_name_input.value.strip()\n",
    "    if not name:\n",
    "        bbox_status.value = \"Введите название территории\"\n",
    "        return\n",
    "    try:\n",
    "        bbox_value = bbox_from_area_name(name)\n",
    "    except Exception as exc:\n",
    "        bbox_status.value = f\"Ошибка: {exc}\"\n",
    "        return\n",
    "    bbox_input.value = bbox_value\n",
    "    bbox_status.value = \"BBox обновлён\"\n",
    "\n",
    "\n",
    "def _results_to_gdf(results: list) -> gpd.GeoDataFrame:\n",
    "    rows = [\n",
    "        {\n",
    "            \"geometry\": res.geometry,\n",
    "            \"location\": res.location,\n",
    "            \"osm_id\": res.osm_id,\n",
    "            \"text\": res.source_text,\n",
    "        }\n",
    "        for res in results\n",
    "        if res.geometry is not None\n",
    "    ]\n",
    "    return gpd.GeoDataFrame(rows, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "\n",
    "def _attach_results(data, results: list):\n",
    "    result = data.copy()\n",
    "    result[\"location\"] = [res.location for res in results]\n",
    "    result[\"osm_id\"] = [res.osm_id for res in results]\n",
    "    result[\"lat\"] = [res.geometry.y if res.geometry is not None else None for res in results]\n",
    "    result[\"lon\"] = [res.geometry.x if res.geometry is not None else None for res in results]\n",
    "    return result\n",
    "\n",
    "\n",
    "def _run_geocoding(_):\n",
    "    geo_output.clear_output()\n",
    "    with geo_output:\n",
    "        csv_path = Path(file_picker.value).expanduser()\n",
    "        if not csv_path.exists():\n",
    "            raise FileNotFoundError(f\"Файл не найден: {csv_path}\")\n",
    "        texts, data, data_type = _load_texts(csv_path)\n",
    "        bbox = bbox_input.value.strip() or None\n",
    "        bbox_name = bbox_name_input.value.strip() or None\n",
    "        results = geocode_texts(texts, bbox=bbox, bbox_name=bbox_name)\n",
    "        target = _ensure_output_path(output_path.value, csv_path)\n",
    "        output_path.value = str(target)\n",
    "\n",
    "        gdf = _results_to_gdf(results)\n",
    "        if data_type == \"csv\":\n",
    "            result_df = _attach_results(data, results)\n",
    "            result_df.to_csv(target, index=False)\n",
    "        elif data_type == \"geojson\":\n",
    "            result_gdf = _attach_results(data, results)\n",
    "            result_gdf.to_file(target, driver=\"GeoJSON\")\n",
    "        else:\n",
    "            geojson_data = build_geojson(results)\n",
    "            save_geojson(target, geojson_data)\n",
    "        display({\"output\": str(target)})\n",
    "\n",
    "        save_map(map_output.value, results)\n",
    "        display({\"map\": map_output.value})\n",
    "\n",
    "        if gdf.empty:\n",
    "            display(\"Нет точек для отображения на карте.\")\n",
    "        else:\n",
    "            display(gdf.explore())\n",
    "\n",
    "\n",
    "upload_button.on_click(_handle_upload)\n",
    "bbox_resolve.on_click(_resolve_bbox)\n",
    "run_geocoder.on_click(_run_geocoding)\n",
    "\n",
    "display(\n",
    "    file_picker,\n",
    "    widgets.HBox([upload_widget, upload_button]),\n",
    "    upload_status,\n",
    "    bbox_input,\n",
    "    widgets.HBox([bbox_name_input, bbox_resolve]),\n",
    "    bbox_status,\n",
    "    output_path,\n",
    "    map_output,\n",
    "    run_geocoder,\n",
    "    geo_output,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация эмоций\n",
    "\n",
    "Определяет эмоции в текстах и сохраняет результат с новой колонкой `emotion`.\n",
    "\n",
    "**Как пользоваться:**\n",
    "1. Укажите путь к CSV/GeoJSON (обычно `parsed_texts.csv`) или загрузите файл.\n",
    "2. Проверьте путь к выходному файлу.\n",
    "3. Нажмите **«Классифицировать»** — получите файл с эмоциями и круговую диаграмму распределения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Классификатор эмоций: импорт и запуск с UI\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/content/digital_identity/parsers\")\n",
    "from emotion_classifier import models_initialization, classify_emotions\n",
    "\n",
    "DEFAULT_INPUT = Path(\"/content/digital_identity/parsed_texts.csv\")\n",
    "UPLOAD_TARGET = Path(\"/content/digital_identity/uploaded_texts\")\n",
    "\n",
    "file_picker = widgets.Text(\n",
    "    value=str(DEFAULT_INPUT),\n",
    "    description=\"CSV/GeoJSON:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "upload_widget = widgets.FileUpload(accept=\".csv,.geojson,.json\", multiple=False)\n",
    "upload_button = widgets.Button(description=\"Загрузить файл\")\n",
    "upload_status = widgets.Label()\n",
    "\n",
    "output_path = widgets.Text(\n",
    "    value=\"/content/digital_identity/emotions_output.csv\",\n",
    "    description=\"Выход:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "chart_output = widgets.Text(\n",
    "    value=\"/content/digital_identity/emotions_chart.png\",\n",
    "    description=\"Диаграмма:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "batch_size = widgets.IntSlider(\n",
    "    value=32,\n",
    "    min=4,\n",
    "    max=128,\n",
    "    step=4,\n",
    "    description=\"Batch:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "progress = widgets.IntProgress(value=0, min=0, max=1, description=\"Прогресс:\")\n",
    "progress_label = widgets.Label()\n",
    "run_classifier = widgets.Button(description=\"Классифицировать\")\n",
    "classifier_output = widgets.Output()\n",
    "\n",
    "\n",
    "def _default_output_path(input_path: Path) -> Path:\n",
    "    suffix = input_path.suffix.lower()\n",
    "    if suffix in {\".geojson\", \".json\"}:\n",
    "        return input_path.with_name(f\"{input_path.stem}_emotions.geojson\")\n",
    "    return input_path.with_name(f\"{input_path.stem}_emotions.csv\")\n",
    "\n",
    "\n",
    "def _ensure_output_path(raw_value: str, input_path: Path) -> Path:\n",
    "    target = Path(raw_value) if raw_value else _default_output_path(input_path)\n",
    "    suffix = \".geojson\" if input_path.suffix.lower() in {\".geojson\", \".json\"} else \".csv\"\n",
    "    if target.suffix.lower() != suffix:\n",
    "        target = target.with_suffix(suffix)\n",
    "    return target\n",
    "\n",
    "\n",
    "def _load_dataset(path: Path):\n",
    "    suffix = path.suffix.lower()\n",
    "    if suffix in {\".geojson\", \".json\"}:\n",
    "        gdf = gpd.read_file(path)\n",
    "        if \"text\" not in gdf.columns:\n",
    "            raise ValueError(\"GeoJSON должен содержать колонку text\")\n",
    "        return gdf, \"geojson\"\n",
    "    if suffix == \".csv\":\n",
    "        df = pd.read_csv(path)\n",
    "        if \"text\" not in df.columns:\n",
    "            raise ValueError(\"CSV должен содержать колонку text\")\n",
    "        return df, \"csv\"\n",
    "    raise ValueError(\"Поддерживаются только CSV или GeoJSON файлы\")\n",
    "\n",
    "\n",
    "def _extract_upload_payload():\n",
    "    upload_value = upload_widget.value\n",
    "    if isinstance(upload_value, dict):\n",
    "        if not upload_value:\n",
    "            return None, None\n",
    "        return next(iter(upload_value.items()))\n",
    "    if isinstance(upload_value, (list, tuple)):\n",
    "        if not upload_value:\n",
    "            return None, None\n",
    "        payload = upload_value[0]\n",
    "        name = payload.get(\"name\") or payload.get(\"metadata\", {}).get(\"name\")\n",
    "        return name, payload\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def _handle_upload(_):\n",
    "    upload_status.value = \"\"\n",
    "    name, payload = _extract_upload_payload()\n",
    "    if not name or not payload:\n",
    "        upload_status.value = \"Выберите файл для загрузки\"\n",
    "        return\n",
    "    suffix = Path(name).suffix or \".csv\"\n",
    "    target = UPLOAD_TARGET.with_suffix(suffix)\n",
    "    target.write_bytes(payload[\"content\"])\n",
    "    file_picker.value = str(target)\n",
    "    upload_status.value = f\"Файл сохранён: {target}\"\n",
    "\n",
    "\n",
    "def _plot_emotions(df: pd.DataFrame) -> None:\n",
    "    counts = df[\"emotion\"].value_counts()\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.pie(counts.values, labels=counts.index, autopct=\"%1.1f%%\")\n",
    "    ax.set_title(\"Распределение эмоций\")\n",
    "    fig.savefig(chart_output.value, bbox_inches=\"tight\")\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _run_classification(_):\n",
    "    classifier_output.clear_output()\n",
    "    with classifier_output:\n",
    "        input_path = Path(file_picker.value).expanduser()\n",
    "        if not input_path.exists():\n",
    "            raise FileNotFoundError(f\"Файл не найден: {input_path}\")\n",
    "        data, data_type = _load_dataset(input_path)\n",
    "        if models_initialization._classification_model is None:\n",
    "            models_initialization.init_models()\n",
    "        texts = data[\"text\"].fillna(\"\").astype(str).tolist()\n",
    "        progress.max = max(1, len(texts))\n",
    "        progress.value = 0\n",
    "        progress_label.value = \"\"\n",
    "\n",
    "        def _update_progress(done: int, total: int) -> None:\n",
    "            progress.value = min(done, progress.max)\n",
    "            progress_label.value = f\"{done}/{total}\"\n",
    "\n",
    "        data[\"emotion\"] = classify_emotions(\n",
    "            texts,\n",
    "            batch_size=batch_size.value,\n",
    "            progress_callback=_update_progress,\n",
    "        )\n",
    "        target = _ensure_output_path(output_path.value, input_path)\n",
    "        output_path.value = str(target)\n",
    "        if data_type == \"geojson\":\n",
    "            data.to_file(target, driver=\"GeoJSON\")\n",
    "        else:\n",
    "            data.to_csv(target, index=False)\n",
    "        display({\"output\": str(target)})\n",
    "        display(data.head())\n",
    "        _plot_emotions(data)\n",
    "\n",
    "\n",
    "upload_button.on_click(_handle_upload)\n",
    "run_classifier.on_click(_run_classification)\n",
    "\n",
    "display(\n",
    "    file_picker,\n",
    "    widgets.HBox([upload_widget, upload_button]),\n",
    "    upload_status,\n",
    "    output_path,\n",
    "    chart_output,\n",
    "    batch_size,\n",
    "    progress,\n",
    "    progress_label,\n",
    "    run_classifier,\n",
    "    classifier_output,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тематическое моделирование (BERTopic)\n",
    "\n",
    "Кластеризует тексты по темам, добавляет номер темы и ключевые слова, строит визуализации.\n",
    "\n",
    "**Как пользоваться:**\n",
    "1. Укажите путь к CSV/GeoJSON или загрузите файл.\n",
    "2. Проверьте имя текстовой колонки (`text`) и, при необходимости, колонку времени.\n",
    "3. Выберите язык/модель и нажмите **«Обработать»**.\n",
    "4. Результаты сохраняются в файл и показываются в таблице и графиках.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title BERTopic: кластеризация тем и визуализация\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "from IPython.display import display\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/content/digital_identity/parsers\")\n",
    "from topic_modeler import attach_topics, train_topic_model\n",
    "from wordcloud_generator import parse_stop_words\n",
    "\n",
    "pio.renderers.default = \"colab\"\n",
    "\n",
    "DEFAULT_INPUT = Path(\"/content/digital_identity/parsed_texts.csv\")\n",
    "UPLOAD_TARGET = Path(\"/content/digital_identity/uploaded_topics\")\n",
    "\n",
    "file_picker = widgets.Text(\n",
    "    value=str(DEFAULT_INPUT),\n",
    "    description=\"CSV/GeoJSON:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "upload_widget = widgets.FileUpload(accept=\".csv,.geojson,.json\", multiple=False)\n",
    "upload_button = widgets.Button(description=\"Загрузить файл\")\n",
    "upload_status = widgets.Label()\n",
    "\n",
    "text_column = widgets.Text(\n",
    "    value=\"text\",\n",
    "    description=\"Колонка текста:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "timestamp_column = widgets.Text(\n",
    "    value=\"\",\n",
    "    description=\"Колонка времени:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "\n",
    "language_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        (\"Многоязычный\", \"multilingual\"),\n",
    "        (\"Русский\", \"russian\"),\n",
    "        (\"English\", \"english\"),\n",
    "    ],\n",
    "    value=\"multilingual\",\n",
    "    description=\"Язык:\",\n",
    ")\n",
    "embedding_model = widgets.Text(\n",
    "    value=\"\",\n",
    "    description=\"Embedding модель:\",\n",
    "    placeholder=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "stop_words = widgets.Text(\n",
    "    value=\"\",\n",
    "    description=\"Стоп-слова:\",\n",
    "    placeholder=\"russian, english, custom\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "\n",
    "cluster_method = widgets.ToggleButtons(\n",
    "    options=[(\"HDBSCAN\", \"hdbscan\"), (\"k-means\", \"kmeans\")],\n",
    "    value=\"hdbscan\",\n",
    "    description=\"Кластеризация:\",\n",
    ")\n",
    "min_topic_size = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=2,\n",
    "    max=50,\n",
    "    step=1,\n",
    "    description=\"Мин. размер темы:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "min_samples = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=1,\n",
    "    max=50,\n",
    "    step=1,\n",
    "    description=\"min_samples:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "n_clusters = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=2,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description=\"k-means k:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "\n",
    "nr_topics = widgets.IntText(\n",
    "    value=0,\n",
    "    description=\"Число тем (0=auto):\",\n",
    ")\n",
    "top_n_keywords = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=3,\n",
    "    max=15,\n",
    "    step=1,\n",
    "    description=\"Ключевые слова:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "reduce_frequent_words = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description=\"Фильтровать частотные слова (TF-IDF)\",\n",
    ")\n",
    "\n",
    "output_path = widgets.Text(\n",
    "    value=\"/content/digital_identity/topics_output.csv\",\n",
    "    description=\"Выход:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "visual_output_dir = widgets.Text(\n",
    "    value=\"/content/digital_identity/topics_visuals\",\n",
    "    description=\"Визуализации:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "\n",
    "visualizations = widgets.SelectMultiple(\n",
    "    options=[\n",
    "        (\"Карта тем\", \"topics\"),\n",
    "        (\"Барчарт\", \"barchart\"),\n",
    "        (\"Иерархия\", \"hierarchy\"),\n",
    "        (\"Тепловая карта\", \"heatmap\"),\n",
    "        (\"Темы во времени\", \"over_time\"),\n",
    "    ],\n",
    "    value=(\"topics\", \"barchart\"),\n",
    "    description=\"Визуализации:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "\n",
    "progress = widgets.IntProgress(value=0, min=0, max=1, description=\"Прогресс:\")\n",
    "run_model = widgets.Button(description=\"Построить темы\")\n",
    "model_output = widgets.Output()\n",
    "\n",
    "\n",
    "def _default_output_path(input_path: Path) -> Path:\n",
    "    suffix = input_path.suffix.lower()\n",
    "    if suffix in {\".geojson\", \".json\"}:\n",
    "        return input_path.with_name(f\"{input_path.stem}_topics.geojson\")\n",
    "    return input_path.with_name(f\"{input_path.stem}_topics.csv\")\n",
    "\n",
    "\n",
    "def _ensure_output_path(raw_value: str, input_path: Path) -> Path:\n",
    "    target = Path(raw_value) if raw_value else _default_output_path(input_path)\n",
    "    suffix = \".geojson\" if input_path.suffix.lower() in {\".geojson\", \".json\"} else \".csv\"\n",
    "    if target.suffix.lower() != suffix:\n",
    "        target = target.with_suffix(suffix)\n",
    "    return target\n",
    "\n",
    "\n",
    "def _load_dataset(path: Path):\n",
    "    suffix = path.suffix.lower()\n",
    "    if suffix in {\".geojson\", \".json\"}:\n",
    "        gdf = gpd.read_file(path)\n",
    "        return gdf, \"geojson\"\n",
    "    if suffix == \".csv\":\n",
    "        df = pd.read_csv(path)\n",
    "        return df, \"csv\"\n",
    "    raise ValueError(\"Поддерживаются только CSV или GeoJSON файлы\")\n",
    "\n",
    "\n",
    "def _parse_stop_words(raw_value: str):\n",
    "    stop_set = parse_stop_words(raw_value)\n",
    "    return sorted(stop_set) if stop_set else None\n",
    "\n",
    "\n",
    "def _extract_upload_payload():\n",
    "    upload_value = upload_widget.value\n",
    "    if isinstance(upload_value, dict):\n",
    "        if not upload_value:\n",
    "            return None, None\n",
    "        return next(iter(upload_value.items()))\n",
    "    if isinstance(upload_value, (list, tuple)):\n",
    "        if not upload_value:\n",
    "            return None, None\n",
    "        payload = upload_value[0]\n",
    "        name = payload.get(\"name\") or payload.get(\"metadata\", {}).get(\"name\")\n",
    "        return name, payload\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def _handle_upload(_):\n",
    "    upload_status.value = \"\"\n",
    "    name, payload = _extract_upload_payload()\n",
    "    if not name or not payload:\n",
    "        upload_status.value = \"Выберите файл для загрузки\"\n",
    "        return\n",
    "    suffix = Path(name).suffix or \".csv\"\n",
    "    target = UPLOAD_TARGET.with_suffix(suffix)\n",
    "    target.write_bytes(payload[\"content\"])\n",
    "    file_picker.value = str(target)\n",
    "    upload_status.value = f\"Файл сохранён: {target}\"\n",
    "\n",
    "\n",
    "def _parse_timestamps(data: pd.DataFrame, column_name: str):\n",
    "    if not column_name:\n",
    "        return None\n",
    "    if column_name not in data.columns:\n",
    "        raise ValueError(f\"Колонка времени '{column_name}' не найдена\")\n",
    "    timestamps = pd.to_datetime(data[column_name], errors=\"coerce\")\n",
    "    if timestamps.isna().all():\n",
    "        raise ValueError(\"Не удалось распознать временные метки\")\n",
    "    return timestamps\n",
    "\n",
    "\n",
    "def _save_plotly_figure(fig, name: str):\n",
    "    output_dir = Path(visual_output_dir.value).expanduser()\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    html_path = output_dir / f\"{name}.html\"\n",
    "    fig.write_html(str(html_path))\n",
    "    image_path = output_dir / f\"{name}.png\"\n",
    "    try:\n",
    "        fig.write_image(str(image_path))\n",
    "    except Exception as exc:\n",
    "        display(f\"Не удалось сохранить PNG: {exc}\")\n",
    "        image_path = None\n",
    "    display({\"html\": str(html_path), \"image\": str(image_path) if image_path else None})\n",
    "\n",
    "\n",
    "def _run_topic_model(_):\n",
    "    model_output.clear_output()\n",
    "    with model_output:\n",
    "        input_path = Path(file_picker.value).expanduser()\n",
    "        if not input_path.exists():\n",
    "            raise FileNotFoundError(f\"Файл не найден: {input_path}\")\n",
    "        data, data_type = _load_dataset(input_path)\n",
    "        text_col = text_column.value.strip() or \"text\"\n",
    "        if text_col not in data.columns:\n",
    "            raise ValueError(f\"Колонка текста '{text_col}' не найдена\")\n",
    "        texts = data[text_col].fillna(\"\").astype(str).tolist()\n",
    "        timestamps = _parse_timestamps(data, timestamp_column.value.strip())\n",
    "\n",
    "        progress.value = 0\n",
    "        result = train_topic_model(\n",
    "            texts,\n",
    "            language=language_dropdown.value,\n",
    "            min_topic_size=min_topic_size.value,\n",
    "            nr_topics=nr_topics.value or None,\n",
    "            embedding_model=embedding_model.value.strip() or None,\n",
    "            stop_words=_parse_stop_words(stop_words.value),\n",
    "            cluster_method=cluster_method.value,\n",
    "            n_clusters=n_clusters.value if cluster_method.value == \"kmeans\" else None,\n",
    "            min_samples=min_samples.value if cluster_method.value == \"hdbscan\" else None,\n",
    "            reduce_frequent_words=reduce_frequent_words.value,\n",
    "        )\n",
    "        data = attach_topics(\n",
    "            data,\n",
    "            result.topics,\n",
    "            result.model,\n",
    "            top_n=top_n_keywords.value,\n",
    "        )\n",
    "\n",
    "        target = _ensure_output_path(output_path.value, input_path)\n",
    "        output_path.value = str(target)\n",
    "        if data_type == \"geojson\":\n",
    "            data.to_file(target, driver=\"GeoJSON\")\n",
    "        else:\n",
    "            data.to_csv(target, index=False)\n",
    "\n",
    "        progress.value = 1\n",
    "        display({\"output\": str(target)})\n",
    "        display(data.head())\n",
    "        topic_info = result.model.get_topic_info()\n",
    "        display(topic_info.head(10))\n",
    "\n",
    "        available_topics = topic_info[topic_info[\"Topic\"] != -1]\n",
    "        topic_count = len(available_topics)\n",
    "\n",
    "        selected = set(visualizations.value)\n",
    "        if \"topics\" in selected:\n",
    "            fig = result.model.visualize_topics()\n",
    "            _save_plotly_figure(fig, f\"{input_path.stem}_topics\")\n",
    "            display(fig)\n",
    "        if \"barchart\" in selected:\n",
    "            fig = result.model.visualize_barchart(top_n_topics=20)\n",
    "            _save_plotly_figure(fig, f\"{input_path.stem}_barchart\")\n",
    "            display(fig)\n",
    "        if \"hierarchy\" in selected:\n",
    "            if topic_count < 2:\n",
    "                display(\"Недостаточно тем для иерархии (нужно минимум 2).\")\n",
    "            else:\n",
    "                fig = result.model.visualize_hierarchy()\n",
    "                _save_plotly_figure(fig, f\"{input_path.stem}_hierarchy\")\n",
    "                display(fig)\n",
    "        if \"heatmap\" in selected:\n",
    "            if topic_count < 2:\n",
    "                display(\"Недостаточно тем для тепловой карты (нужно минимум 2).\")\n",
    "            else:\n",
    "                fig = result.model.visualize_heatmap()\n",
    "                _save_plotly_figure(fig, f\"{input_path.stem}_heatmap\")\n",
    "                display(fig)\n",
    "        if \"over_time\" in selected:\n",
    "            if timestamps is None:\n",
    "                display(\"Для динамики тем укажите колонку времени.\")\n",
    "            else:\n",
    "                topics_over_time = result.model.topics_over_time(\n",
    "                    texts, timestamps, nr_bins=20\n",
    "                )\n",
    "                fig = result.model.visualize_topics_over_time(topics_over_time)\n",
    "                _save_plotly_figure(fig, f\"{input_path.stem}_over_time\")\n",
    "                display(fig)\n",
    "\n",
    "\n",
    "def _toggle_cluster_controls(change=None):\n",
    "    is_kmeans = cluster_method.value == \"kmeans\"\n",
    "    n_clusters.layout.display = \"\" if is_kmeans else \"none\"\n",
    "    min_samples.layout.display = \"none\" if is_kmeans else \"\"\n",
    "\n",
    "\n",
    "cluster_method.observe(_toggle_cluster_controls, names=\"value\")\n",
    "_toggle_cluster_controls()\n",
    "\n",
    "upload_button.on_click(_handle_upload)\n",
    "run_model.on_click(_run_topic_model)\n",
    "\n",
    "display(\n",
    "    file_picker,\n",
    "    widgets.HBox([upload_widget, upload_button]),\n",
    "    upload_status,\n",
    "    text_column,\n",
    "    timestamp_column,\n",
    "    language_dropdown,\n",
    "    embedding_model,\n",
    "    stop_words,\n",
    "    cluster_method,\n",
    "    min_topic_size,\n",
    "    min_samples,\n",
    "    n_clusters,\n",
    "    nr_topics,\n",
    "    top_n_keywords,\n",
    "    reduce_frequent_words,\n",
    "    output_path,\n",
    "    visual_output_dir,\n",
    "    visualizations,\n",
    "    progress,\n",
    "    run_model,\n",
    "    model_output,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Извлечение ключевых слов (KeyBERT)\n",
    "\n",
    "Извлекает ключевые слова из текстов и сохраняет их в итоговый файл.\n",
    "\n",
    "**Как пользоваться:**\n",
    "1. Укажите путь к CSV/GeoJSON или загрузите файл.\n",
    "2. Проверьте колонку текста, при необходимости укажите модель эмбеддингов.\n",
    "3. Настройте стоп‑слова, n‑граммы и параметры MMR/MaxSum.\n",
    "4. Нажмите **«Извлечь ключевые слова»** — в выходном файле появится колонка с ключевыми словами, также строится топ‑лист.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#@title KeyBERT: извлечение ключевых слов и визуализация\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from IPython.display import display\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/content/digital_identity/parsers\")\n",
    "from keybert_modeler import attach_keywords, extract_keywords\n",
    "from wordcloud_generator import parse_stop_words\n",
    "\n",
    "pio.renderers.default = \"colab\"\n",
    "\n",
    "DEFAULT_INPUT = Path(\"/content/digital_identity/parsed_texts.csv\")\n",
    "UPLOAD_TARGET = Path(\"/content/digital_identity/uploaded_keywords\")\n",
    "\n",
    "file_picker = widgets.Text(\n",
    "    value=str(DEFAULT_INPUT),\n",
    "    description=\"CSV/GeoJSON:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "upload_widget = widgets.FileUpload(accept=\".csv,.geojson,.json\", multiple=False)\n",
    "upload_button = widgets.Button(description=\"Загрузить файл\")\n",
    "upload_status = widgets.Label()\n",
    "\n",
    "text_column = widgets.Text(\n",
    "    value=\"text\",\n",
    "    description=\"Колонка текста:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "\n",
    "embedding_model = widgets.Text(\n",
    "    value=\"\",\n",
    "    description=\"Embedding модель:\",\n",
    "    placeholder=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "\n",
    "stop_words = widgets.Text(\n",
    "    value=\"\",\n",
    "    description=\"Стоп-слова:\",\n",
    "    placeholder=\"russian, english, custom\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "\n",
    "ngram_min = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=3,\n",
    "    step=1,\n",
    "    description=\"n-gram мин:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "ngram_max = widgets.IntSlider(\n",
    "    value=2,\n",
    "    min=1,\n",
    "    max=4,\n",
    "    step=1,\n",
    "    description=\"n-gram макс:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "\n",
    "keywords_top_n = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=3,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description=\"Ключевые слова:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "\n",
    "use_mmr = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description=\"MMR\",\n",
    ")\n",
    "\n",
    "diversity = widgets.FloatSlider(\n",
    "    value=0.5,\n",
    "    min=0.1,\n",
    "    max=0.9,\n",
    "    step=0.1,\n",
    "    description=\"Diversity:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "\n",
    "use_maxsum = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description=\"MaxSum\",\n",
    ")\n",
    "\n",
    "nr_candidates = widgets.IntSlider(\n",
    "    value=20,\n",
    "    min=5,\n",
    "    max=50,\n",
    "    step=1,\n",
    "    description=\"Кандидаты:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "\n",
    "output_path = widgets.Text(\n",
    "    value=\"/content/digital_identity/keywords_output.csv\",\n",
    "    description=\"Выход:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "visual_output_dir = widgets.Text(\n",
    "    value=\"/content/digital_identity/keywords_visuals\",\n",
    "    description=\"Визуализации:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "\n",
    "visualizations = widgets.SelectMultiple(\n",
    "    options=[\n",
    "        (\"Топ ключевых слов\", \"top_keywords\"),\n",
    "    ],\n",
    "    value=(\"top_keywords\",),\n",
    "    description=\"Визуализации:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "\n",
    "progress = widgets.IntProgress(value=0, min=0, max=1, description=\"Прогресс:\")\n",
    "run_model = widgets.Button(description=\"Извлечь ключевые слова\")\n",
    "model_output = widgets.Output()\n",
    "\n",
    "\n",
    "def _default_output_path(input_path: Path) -> Path:\n",
    "    suffix = input_path.suffix.lower()\n",
    "    if suffix in {\".geojson\", \".json\"}:\n",
    "        return input_path.with_name(f\"{input_path.stem}_keywords.geojson\")\n",
    "    return input_path.with_name(f\"{input_path.stem}_keywords.csv\")\n",
    "\n",
    "\n",
    "def _ensure_output_path(raw_value: str, input_path: Path) -> Path:\n",
    "    target = Path(raw_value) if raw_value else _default_output_path(input_path)\n",
    "    suffix = \".geojson\" if input_path.suffix.lower() in {\".geojson\", \".json\"} else \".csv\"\n",
    "    if target.suffix.lower() != suffix:\n",
    "        target = target.with_suffix(suffix)\n",
    "    return target\n",
    "\n",
    "\n",
    "def _load_dataset(path: Path):\n",
    "    suffix = path.suffix.lower()\n",
    "    if suffix in {\".geojson\", \".json\"}:\n",
    "        gdf = gpd.read_file(path)\n",
    "        return gdf, \"geojson\"\n",
    "    if suffix == \".csv\":\n",
    "        df = pd.read_csv(path)\n",
    "        return df, \"csv\"\n",
    "    raise ValueError(\"Поддерживаются только CSV или GeoJSON файлы\")\n",
    "\n",
    "\n",
    "def _parse_stop_words(raw_value: str):\n",
    "    stop_set = parse_stop_words(raw_value)\n",
    "    return sorted(stop_set) if stop_set else None\n",
    "\n",
    "\n",
    "def _extract_upload_payload():\n",
    "    upload_value = upload_widget.value\n",
    "    if isinstance(upload_value, dict):\n",
    "        if not upload_value:\n",
    "            return None, None\n",
    "        return next(iter(upload_value.items()))\n",
    "    if isinstance(upload_value, (list, tuple)):\n",
    "        if not upload_value:\n",
    "            return None, None\n",
    "        payload = upload_value[0]\n",
    "        name = payload.get(\"name\") or payload.get(\"metadata\", {}).get(\"name\")\n",
    "        return name, payload\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def _handle_upload(_):\n",
    "    upload_status.value = \"\"\n",
    "    name, payload = _extract_upload_payload()\n",
    "    if not name or not payload:\n",
    "        upload_status.value = \"Выберите файл для загрузки\"\n",
    "        return\n",
    "    suffix = Path(name).suffix or \".csv\"\n",
    "    target = UPLOAD_TARGET.with_suffix(suffix)\n",
    "    target.write_bytes(payload[\"content\"])\n",
    "    file_picker.value = str(target)\n",
    "    upload_status.value = f\"Файл сохранён: {target}\"\n",
    "\n",
    "\n",
    "def _save_plotly_figure(fig, name: str):\n",
    "    output_dir = Path(visual_output_dir.value).expanduser()\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    html_path = output_dir / f\"{name}.html\"\n",
    "    fig.write_html(str(html_path))\n",
    "    image_path = output_dir / f\"{name}.png\"\n",
    "    try:\n",
    "        fig.write_image(str(image_path))\n",
    "    except Exception as exc:\n",
    "        display(f\"Не удалось сохранить PNG: {exc}\")\n",
    "        image_path = None\n",
    "    display({\"html\": str(html_path), \"image\": str(image_path) if image_path else None})\n",
    "\n",
    "\n",
    "def _run_keybert(_):\n",
    "    model_output.clear_output()\n",
    "    with model_output:\n",
    "        input_path = Path(file_picker.value).expanduser()\n",
    "        if not input_path.exists():\n",
    "            raise FileNotFoundError(f\"Файл не найден: {input_path}\")\n",
    "        data, data_type = _load_dataset(input_path)\n",
    "        text_col = text_column.value.strip() or \"text\"\n",
    "        if text_col not in data.columns:\n",
    "            raise ValueError(f\"Колонка текста '{text_col}' не найдена\")\n",
    "        texts = data[text_col].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "        progress.max = max(1, len(texts))\n",
    "        progress.value = 0\n",
    "\n",
    "        def _update_progress(done: int, total: int) -> None:\n",
    "            progress.value = min(done, progress.max)\n",
    "\n",
    "        result = extract_keywords(\n",
    "            texts,\n",
    "            embedding_model=embedding_model.value.strip() or None,\n",
    "            top_n=keywords_top_n.value,\n",
    "            keyphrase_ngram_range=(ngram_min.value, ngram_max.value),\n",
    "            stop_words=_parse_stop_words(stop_words.value),\n",
    "            use_mmr=use_mmr.value,\n",
    "            diversity=diversity.value,\n",
    "            use_maxsum=use_maxsum.value,\n",
    "            nr_candidates=nr_candidates.value,\n",
    "            progress_callback=_update_progress,\n",
    "        )\n",
    "        data = attach_keywords(data, result.keywords)\n",
    "\n",
    "        target = _ensure_output_path(output_path.value, input_path)\n",
    "        output_path.value = str(target)\n",
    "        if data_type == \"geojson\":\n",
    "            data.to_file(target, driver=\"GeoJSON\")\n",
    "        else:\n",
    "            data.to_csv(target, index=False)\n",
    "\n",
    "        display({\"output\": str(target)})\n",
    "        display(data.head())\n",
    "\n",
    "        if \"top_keywords\" in set(visualizations.value):\n",
    "            freq = {}\n",
    "            for keyword_list in result.keywords:\n",
    "                for keyword, _ in keyword_list:\n",
    "                    freq[keyword] = freq.get(keyword, 0) + 1\n",
    "            if not freq:\n",
    "                display(\"Нет ключевых слов для визуализации.\")\n",
    "            else:\n",
    "                freq_df = (\n",
    "                    pd.DataFrame(\n",
    "                        [{\"keyword\": k, \"count\": v} for k, v in freq.items()]\n",
    "                    )\n",
    "                    .sort_values(\"count\", ascending=False)\n",
    "                    .head(30)\n",
    "                )\n",
    "                fig = px.bar(freq_df, x=\"keyword\", y=\"count\", title=\"Топ ключевых слов\")\n",
    "                fig.update_layout(xaxis_tickangle=-45)\n",
    "                _save_plotly_figure(fig, f\"{input_path.stem}_keywords\")\n",
    "                display(fig)\n",
    "\n",
    "\n",
    "upload_button.on_click(_handle_upload)\n",
    "run_model.on_click(_run_keybert)\n",
    "\n",
    "display(\n",
    "    file_picker,\n",
    "    widgets.HBox([upload_widget, upload_button]),\n",
    "    upload_status,\n",
    "    text_column,\n",
    "    embedding_model,\n",
    "    stop_words,\n",
    "    widgets.HBox([ngram_min, ngram_max]),\n",
    "    keywords_top_n,\n",
    "    use_mmr,\n",
    "    diversity,\n",
    "    use_maxsum,\n",
    "    nr_candidates,\n",
    "    output_path,\n",
    "    visual_output_dir,\n",
    "    visualizations,\n",
    "    progress,\n",
    "    run_model,\n",
    "    model_output,\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Семантическая лепестковая диаграмма\n",
    "\n",
    "Оценивает тексты по заданным осям (до 10) и строит лепестковую диаграмму по средним значениям.\n",
    "\n",
    "**Как пользоваться:**\n",
    "1. Укажите путь к CSV/GeoJSON и колонку текста.\n",
    "2. Опишите оси в формате `Название | левые слова | правые слова` (каждая ось в отдельной строке).\n",
    "3. Нажмите **«Построить»** — получите таблицу оценок и диаграмму.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#@title Семантическая лепестковая диаграмма: оценка по осям и визуализация\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "from IPython.display import display\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/content/digital_identity/parsers\")\n",
    "from semantic_axes import build_radar_chart, parse_axis_lines, score_texts_on_axes\n",
    "\n",
    "pio.renderers.default = \"colab\"\n",
    "\n",
    "DEFAULT_INPUT = Path(\"/content/digital_identity/parsed_texts.csv\")\n",
    "UPLOAD_TARGET = Path(\"/content/digital_identity/uploaded_semantic_axes\")\n",
    "\n",
    "\n",
    "def load_table(path: Path) -> pd.DataFrame:\n",
    "    if path.suffix.lower() in {\".geojson\", \".json\"}:\n",
    "        return gpd.read_file(path)\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "\n",
    "upload = widgets.FileUpload(accept=\".csv,.geojson,.json\", multiple=False)\n",
    "upload_button = widgets.Button(description=\"Загрузить файл\")\n",
    "upload_status = widgets.Label()\n",
    "input_path_widget = widgets.Text(value=str(DEFAULT_INPUT), description=\"Путь:\")\n",
    "text_column_widget = widgets.Text(value=\"text\", description=\"Колонка:\")\n",
    "axes_widget = widgets.Textarea(\n",
    "    value=\"Ось 1 | негатив, плохой | позитив, хороший\\nОсь 2 | медленно | быстро\",\n",
    "    description=\"Оси:\",\n",
    "    layout=widgets.Layout(width=\"100%\", height=\"120px\"),\n",
    ")\n",
    "model_widget = widgets.Text(\n",
    "    value=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    description=\"Модель:\",\n",
    ")\n",
    "output_path = widgets.Text(\n",
    "    value=\"/content/digital_identity/semantic_axes_output.csv\",\n",
    "    description=\"Выход:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "visual_output_dir = widgets.Text(\n",
    "    value=\"/content/digital_identity/semantic_axes_visuals\",\n",
    "    description=\"Визуализации:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "progress = widgets.IntProgress(value=0, min=0, max=1, description=\"Прогресс:\")\n",
    "run_button = widgets.Button(description=\"Построить\")\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "def _default_output_path(input_path: Path) -> Path:\n",
    "    suffix = input_path.suffix.lower()\n",
    "    if suffix in {\".geojson\", \".json\"}:\n",
    "        return input_path.with_name(f\"{input_path.stem}_semantic_axes.geojson\")\n",
    "    return input_path.with_name(f\"{input_path.stem}_semantic_axes.csv\")\n",
    "\n",
    "\n",
    "def _ensure_output_path(raw_value: str, input_path: Path) -> Path:\n",
    "    target = Path(raw_value) if raw_value else _default_output_path(input_path)\n",
    "    suffix = \".geojson\" if input_path.suffix.lower() in {\".geojson\", \".json\"} else \".csv\"\n",
    "    if target.suffix.lower() != suffix:\n",
    "        target = target.with_suffix(suffix)\n",
    "    return target\n",
    "\n",
    "\n",
    "def _extract_upload_payload():\n",
    "    upload_value = upload.value\n",
    "    if isinstance(upload_value, dict):\n",
    "        if not upload_value:\n",
    "            return None, None\n",
    "        return next(iter(upload_value.items()))\n",
    "    if isinstance(upload_value, (list, tuple)):\n",
    "        if not upload_value:\n",
    "            return None, None\n",
    "        payload = upload_value[0]\n",
    "        name = payload.get(\"name\") or payload.get(\"metadata\", {}).get(\"name\")\n",
    "        return name, payload\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def _handle_upload(_):\n",
    "    upload_status.value = \"\"\n",
    "    name, payload = _extract_upload_payload()\n",
    "    if not name or not payload:\n",
    "        upload_status.value = \"Выберите файл для загрузки\"\n",
    "        return\n",
    "    suffix = Path(name).suffix or \".csv\"\n",
    "    target = UPLOAD_TARGET.with_suffix(suffix)\n",
    "    target.write_bytes(payload[\"content\"])\n",
    "    input_path_widget.value = str(target)\n",
    "    upload_status.value = f\"Файл сохранён: {target}\"\n",
    "\n",
    "\n",
    "def _save_plotly_figure(fig, name: str):\n",
    "    output_dir = Path(visual_output_dir.value).expanduser()\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    html_path = output_dir / f\"{name}.html\"\n",
    "    fig.write_html(str(html_path))\n",
    "    image_path = output_dir / f\"{name}.png\"\n",
    "    try:\n",
    "        fig.write_image(str(image_path))\n",
    "    except Exception as exc:\n",
    "        display(f\"Не удалось сохранить PNG: {exc}\")\n",
    "        image_path = None\n",
    "    display({\"html\": str(html_path), \"image\": str(image_path) if image_path else None})\n",
    "\n",
    "\n",
    "def on_run(_):\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        input_path = Path(input_path_widget.value).expanduser()\n",
    "        data = load_table(input_path)\n",
    "        text_col = text_column_widget.value.strip() or \"text\"\n",
    "        if text_col not in data.columns:\n",
    "            raise ValueError(f\"Колонка текста '{text_col}' не найдена\")\n",
    "        texts = data[text_col].fillna(\"\").astype(str).tolist()\n",
    "        axes = parse_axis_lines(axes_widget.value)\n",
    "        if len(axes) > 10:\n",
    "            raise ValueError(\"Максимум 10 осей.\")\n",
    "        progress.value = 0\n",
    "        scores = score_texts_on_axes(texts, axes, model_name=model_widget.value, show_progress=True)\n",
    "        progress.value = 1\n",
    "        average = scores.mean()\n",
    "        display(scores.head())\n",
    "        display(pd.DataFrame({\"axis\": average.index, \"mean_score\": average.values}))\n",
    "\n",
    "        result = data.copy()\n",
    "        for column in scores.columns:\n",
    "            result[column] = scores[column].values\n",
    "\n",
    "        target = _ensure_output_path(output_path.value, input_path)\n",
    "        output_path.value = str(target)\n",
    "        if input_path.suffix.lower() in {\".geojson\", \".json\"}:\n",
    "            result.to_file(target, driver=\"GeoJSON\")\n",
    "        else:\n",
    "            result.to_csv(target, index=False)\n",
    "        display({\"output\": str(target)})\n",
    "\n",
    "        fig = build_radar_chart(average)\n",
    "        _save_plotly_figure(fig, f\"{input_path.stem}_semantic_axes\")\n",
    "        fig.show()\n",
    "\n",
    "\n",
    "upload_button.on_click(_handle_upload)\n",
    "run_button.on_click(on_run)\n",
    "\n",
    "display(\n",
    "    widgets.VBox([\n",
    "        widgets.HBox([upload, upload_button]),\n",
    "        upload_status,\n",
    "        input_path_widget,\n",
    "        text_column_widget,\n",
    "        axes_widget,\n",
    "        model_widget,\n",
    "        output_path,\n",
    "        visual_output_dir,\n",
    "        progress,\n",
    "        run_button,\n",
    "        output,\n",
    "    ])\n",
    ")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Семантическая карта\n",
    "\n",
    "Строит карту по двум осям (оси трактуются как диаметры, центр находится в нуле).\n",
    "\n",
    "**Как пользоваться:**\n",
    "1. Укажите путь к CSV/GeoJSON и колонку текста.\n",
    "2. Задайте ровно две оси в формате `Название | левые слова | правые слова`.\n",
    "3. Нажмите **«Построить»** — получите точки на карте, где оси пересекаются в центре.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#@title Семантическая карта: оценка по двум осям и визуализация\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "from IPython.display import display\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/content/digital_identity/parsers\")\n",
    "from semantic_axes import build_semantic_map, parse_axis_lines, score_texts_on_axes\n",
    "\n",
    "pio.renderers.default = \"colab\"\n",
    "\n",
    "DEFAULT_INPUT = Path(\"/content/digital_identity/parsed_texts.csv\")\n",
    "UPLOAD_TARGET = Path(\"/content/digital_identity/uploaded_semantic_map\")\n",
    "\n",
    "\n",
    "def load_table(path: Path) -> pd.DataFrame:\n",
    "    if path.suffix.lower() in {\".geojson\", \".json\"}:\n",
    "        return gpd.read_file(path)\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "\n",
    "upload = widgets.FileUpload(accept=\".csv,.geojson,.json\", multiple=False)\n",
    "upload_button = widgets.Button(description=\"Загрузить файл\")\n",
    "upload_status = widgets.Label()\n",
    "input_path_widget = widgets.Text(value=str(DEFAULT_INPUT), description=\"Путь:\")\n",
    "text_column_widget = widgets.Text(value=\"text\", description=\"Колонка:\")\n",
    "axes_widget = widgets.Textarea(\n",
    "    value=\"Ось X | низкий | высокий\\nОсь Y | холодный | тёплый\",\n",
    "    description=\"Оси:\",\n",
    "    layout=widgets.Layout(width=\"100%\", height=\"120px\"),\n",
    ")\n",
    "model_widget = widgets.Text(\n",
    "    value=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    description=\"Модель:\",\n",
    ")\n",
    "output_path = widgets.Text(\n",
    "    value=\"/content/digital_identity/semantic_map_output.csv\",\n",
    "    description=\"Выход:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "visual_output_dir = widgets.Text(\n",
    "    value=\"/content/digital_identity/semantic_map_visuals\",\n",
    "    description=\"Визуализации:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "progress = widgets.IntProgress(value=0, min=0, max=1, description=\"Прогресс:\")\n",
    "run_button = widgets.Button(description=\"Построить\")\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "def _default_output_path(input_path: Path) -> Path:\n",
    "    suffix = input_path.suffix.lower()\n",
    "    if suffix in {\".geojson\", \".json\"}:\n",
    "        return input_path.with_name(f\"{input_path.stem}_semantic_map.geojson\")\n",
    "    return input_path.with_name(f\"{input_path.stem}_semantic_map.csv\")\n",
    "\n",
    "\n",
    "def _ensure_output_path(raw_value: str, input_path: Path) -> Path:\n",
    "    target = Path(raw_value) if raw_value else _default_output_path(input_path)\n",
    "    suffix = \".geojson\" if input_path.suffix.lower() in {\".geojson\", \".json\"} else \".csv\"\n",
    "    if target.suffix.lower() != suffix:\n",
    "        target = target.with_suffix(suffix)\n",
    "    return target\n",
    "\n",
    "\n",
    "def _extract_upload_payload():\n",
    "    upload_value = upload.value\n",
    "    if isinstance(upload_value, dict):\n",
    "        if not upload_value:\n",
    "            return None, None\n",
    "        return next(iter(upload_value.items()))\n",
    "    if isinstance(upload_value, (list, tuple)):\n",
    "        if not upload_value:\n",
    "            return None, None\n",
    "        payload = upload_value[0]\n",
    "        name = payload.get(\"name\") or payload.get(\"metadata\", {}).get(\"name\")\n",
    "        return name, payload\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def _handle_upload(_):\n",
    "    upload_status.value = \"\"\n",
    "    name, payload = _extract_upload_payload()\n",
    "    if not name or not payload:\n",
    "        upload_status.value = \"Выберите файл для загрузки\"\n",
    "        return\n",
    "    suffix = Path(name).suffix or \".csv\"\n",
    "    target = UPLOAD_TARGET.with_suffix(suffix)\n",
    "    target.write_bytes(payload[\"content\"])\n",
    "    input_path_widget.value = str(target)\n",
    "    upload_status.value = f\"Файл сохранён: {target}\"\n",
    "\n",
    "\n",
    "def _save_plotly_figure(fig, name: str):\n",
    "    output_dir = Path(visual_output_dir.value).expanduser()\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    html_path = output_dir / f\"{name}.html\"\n",
    "    fig.write_html(str(html_path))\n",
    "    image_path = output_dir / f\"{name}.png\"\n",
    "    try:\n",
    "        fig.write_image(str(image_path))\n",
    "    except Exception as exc:\n",
    "        display(f\"Не удалось сохранить PNG: {exc}\")\n",
    "        image_path = None\n",
    "    display({\"html\": str(html_path), \"image\": str(image_path) if image_path else None})\n",
    "\n",
    "\n",
    "def on_run(_):\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        input_path = Path(input_path_widget.value).expanduser()\n",
    "        data = load_table(input_path)\n",
    "        text_col = text_column_widget.value.strip() or \"text\"\n",
    "        if text_col not in data.columns:\n",
    "            raise ValueError(f\"Колонка текста '{text_col}' не найдена\")\n",
    "        texts = data[text_col].fillna(\"\").astype(str).tolist()\n",
    "        axes = parse_axis_lines(axes_widget.value)\n",
    "        if len(axes) != 2:\n",
    "            raise ValueError(\"Для карты нужно ровно две оси.\")\n",
    "        progress.value = 0\n",
    "        scores = score_texts_on_axes(texts, axes, model_name=model_widget.value, show_progress=True)\n",
    "        progress.value = 1\n",
    "        axis_x, axis_y = scores.columns.tolist()\n",
    "        display(scores.head())\n",
    "\n",
    "        result = data.copy()\n",
    "        for column in scores.columns:\n",
    "            result[column] = scores[column].values\n",
    "        target = _ensure_output_path(output_path.value, input_path)\n",
    "        output_path.value = str(target)\n",
    "        if input_path.suffix.lower() in {\".geojson\", \".json\"}:\n",
    "            result.to_file(target, driver=\"GeoJSON\")\n",
    "        else:\n",
    "            result.to_csv(target, index=False)\n",
    "        display({\"output\": str(target)})\n",
    "\n",
    "        fig = build_semantic_map(scores, texts, axis_x=axis_x, axis_y=axis_y)\n",
    "        _save_plotly_figure(fig, f\"{input_path.stem}_semantic_map\")\n",
    "        fig.show()\n",
    "\n",
    "\n",
    "upload_button.on_click(_handle_upload)\n",
    "run_button.on_click(on_run)\n",
    "\n",
    "display(\n",
    "    widgets.VBox([\n",
    "        widgets.HBox([upload, upload_button]),\n",
    "        upload_status,\n",
    "        input_path_widget,\n",
    "        text_column_widget,\n",
    "        axes_widget,\n",
    "        model_widget,\n",
    "        output_path,\n",
    "        visual_output_dir,\n",
    "        progress,\n",
    "        run_button,\n",
    "        output,\n",
    "    ])\n",
    ")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Облако слов\n",
    "\n",
    "Строит облако слов по колонке `text` в CSV/GeoJSON.\n",
    "\n",
    "**Как пользоваться:**\n",
    "1. Укажите путь к CSV/GeoJSON или загрузите файл.\n",
    "2. Проверьте колонку текста, задайте стоп‑слова (например, `russian` или список через запятую).\n",
    "3. Нажмите **«Построить»** — отобразится облако слов и сохранится изображение.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#@title Облако слов: генерация и визуализация\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/content/digital_identity/parsers\")\n",
    "from wordcloud_generator import build_wordcloud\n",
    "\n",
    "DEFAULT_INPUT = Path(\"/content/digital_identity/parsed_texts.csv\")\n",
    "UPLOAD_TARGET = Path(\"/content/digital_identity/uploaded_wordcloud\")\n",
    "\n",
    "file_picker = widgets.Text(\n",
    "    value=str(DEFAULT_INPUT),\n",
    "    description=\"CSV/GeoJSON:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "upload_widget = widgets.FileUpload(accept=\".csv,.geojson,.json\", multiple=False)\n",
    "upload_button = widgets.Button(description=\"Загрузить файл\")\n",
    "upload_status = widgets.Label()\n",
    "\n",
    "text_column = widgets.Text(\n",
    "    value=\"text\",\n",
    "    description=\"Колонка текста:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "\n",
    "stop_words = widgets.Text(\n",
    "    value=\"russian\",\n",
    "    description=\"Стоп-слова:\",\n",
    "    placeholder=\"russian, english, custom\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "\n",
    "max_words = widgets.IntSlider(\n",
    "    value=200,\n",
    "    min=50,\n",
    "    max=500,\n",
    "    step=10,\n",
    "    description=\"Макс. слов:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "\n",
    "width = widgets.IntSlider(\n",
    "    value=800,\n",
    "    min=400,\n",
    "    max=1200,\n",
    "    step=50,\n",
    "    description=\"Ширина:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "height = widgets.IntSlider(\n",
    "    value=400,\n",
    "    min=200,\n",
    "    max=800,\n",
    "    step=50,\n",
    "    description=\"Высота:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "\n",
    "background_color = widgets.Text(\n",
    "    value=\"white\",\n",
    "    description=\"Фон:\",\n",
    "    layout=widgets.Layout(width=\"60%\"),\n",
    ")\n",
    "\n",
    "output_path = widgets.Text(\n",
    "    value=\"/content/digital_identity/wordcloud_output.csv\",\n",
    "    description=\"Выход:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "image_output = widgets.Text(\n",
    "    value=\"/content/digital_identity/wordcloud.png\",\n",
    "    description=\"Картинка:\",\n",
    "    layout=widgets.Layout(width=\"80%\"),\n",
    ")\n",
    "progress = widgets.IntProgress(value=0, min=0, max=1, description=\"Прогресс:\")\n",
    "run_wordcloud = widgets.Button(description=\"Построить облако\")\n",
    "wordcloud_output = widgets.Output()\n",
    "\n",
    "\n",
    "def _default_output_path(input_path: Path) -> Path:\n",
    "    suffix = input_path.suffix.lower()\n",
    "    if suffix in {\".geojson\", \".json\"}:\n",
    "        return input_path.with_name(f\"{input_path.stem}_wordcloud.geojson\")\n",
    "    return input_path.with_name(f\"{input_path.stem}_wordcloud.csv\")\n",
    "\n",
    "\n",
    "def _ensure_output_path(raw_value: str, input_path: Path) -> Path:\n",
    "    target = Path(raw_value) if raw_value else _default_output_path(input_path)\n",
    "    suffix = \".geojson\" if input_path.suffix.lower() in {\".geojson\", \".json\"} else \".csv\"\n",
    "    if target.suffix.lower() != suffix:\n",
    "        target = target.with_suffix(suffix)\n",
    "    return target\n",
    "\n",
    "\n",
    "def _load_dataset(path: Path):\n",
    "    suffix = path.suffix.lower()\n",
    "    if suffix in {\".geojson\", \".json\"}:\n",
    "        gdf = gpd.read_file(path)\n",
    "        return gdf, \"geojson\"\n",
    "    if suffix == \".csv\":\n",
    "        df = pd.read_csv(path)\n",
    "        return df, \"csv\"\n",
    "    raise ValueError(\"Поддерживаются только CSV или GeoJSON файлы\")\n",
    "\n",
    "\n",
    "def _extract_upload_payload():\n",
    "    upload_value = upload_widget.value\n",
    "    if isinstance(upload_value, dict):\n",
    "        if not upload_value:\n",
    "            return None, None\n",
    "        return next(iter(upload_value.items()))\n",
    "    if isinstance(upload_value, (list, tuple)):\n",
    "        if not upload_value:\n",
    "            return None, None\n",
    "        payload = upload_value[0]\n",
    "        name = payload.get(\"name\") or payload.get(\"metadata\", {}).get(\"name\")\n",
    "        return name, payload\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def _handle_upload(_):\n",
    "    upload_status.value = \"\"\n",
    "    name, payload = _extract_upload_payload()\n",
    "    if not name or not payload:\n",
    "        upload_status.value = \"Выберите файл для загрузки\"\n",
    "        return\n",
    "    suffix = Path(name).suffix or \".csv\"\n",
    "    target = UPLOAD_TARGET.with_suffix(suffix)\n",
    "    target.write_bytes(payload[\"content\"])\n",
    "    file_picker.value = str(target)\n",
    "    upload_status.value = f\"Файл сохранён: {target}\"\n",
    "\n",
    "\n",
    "def _run_wordcloud(_):\n",
    "    wordcloud_output.clear_output()\n",
    "    with wordcloud_output:\n",
    "        input_path = Path(file_picker.value).expanduser()\n",
    "        if not input_path.exists():\n",
    "            raise FileNotFoundError(f\"Файл не найден: {input_path}\")\n",
    "        data, data_type = _load_dataset(input_path)\n",
    "        text_col = text_column.value.strip() or \"text\"\n",
    "        if text_col not in data.columns:\n",
    "            raise ValueError(f\"Колонка текста '{text_col}' не найдена\")\n",
    "        texts = data[text_col].fillna(\"\").astype(str).tolist()\n",
    "        progress.value = 0\n",
    "        result = build_wordcloud(\n",
    "            texts,\n",
    "            stop_words=stop_words.value,\n",
    "            max_words=max_words.value,\n",
    "            width=width.value,\n",
    "            height=height.value,\n",
    "            background_color=background_color.value.strip() or \"white\",\n",
    "        )\n",
    "        progress.value = 1\n",
    "\n",
    "        freq_df = (\n",
    "            pd.DataFrame(\n",
    "                [{\"word\": word, \"weight\": weight} for word, weight in result.wordcloud.words_.items()]\n",
    "            )\n",
    "            .sort_values(\"weight\", ascending=False)\n",
    "        )\n",
    "        target = _ensure_output_path(output_path.value, input_path)\n",
    "        output_path.value = str(target)\n",
    "        if data_type == \"geojson\":\n",
    "            gdf = gpd.GeoDataFrame(freq_df, geometry=[None] * len(freq_df), crs=\"EPSG:4326\")\n",
    "            gdf.to_file(target, driver=\"GeoJSON\")\n",
    "        else:\n",
    "            freq_df.to_csv(target, index=False)\n",
    "        display({\"output\": str(target)})\n",
    "\n",
    "        result.wordcloud.to_file(image_output.value)\n",
    "        display({\"image\": image_output.value})\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(width.value / 100, height.value / 100))\n",
    "        ax.imshow(result.wordcloud, interpolation=\"bilinear\")\n",
    "        ax.axis(\"off\")\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "upload_button.on_click(_handle_upload)\n",
    "run_wordcloud.on_click(_run_wordcloud)\n",
    "\n",
    "display(\n",
    "    file_picker,\n",
    "    widgets.HBox([upload_widget, upload_button]),\n",
    "    upload_status,\n",
    "    text_column,\n",
    "    stop_words,\n",
    "    max_words,\n",
    "    widgets.HBox([width, height]),\n",
    "    background_color,\n",
    "    output_path,\n",
    "    image_output,\n",
    "    progress,\n",
    "    run_wordcloud,\n",
    "    wordcloud_output,\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "name": "text_parsing_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}