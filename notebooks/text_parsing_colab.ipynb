{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Парсинг текстов с сайтов и соцсетей\n\nЭтот блокнот загружает скрипты из репозитория и помогает быстро получить тексты из:\n- статей и страниц сайтов (универсальный парсер)\n- отзывов Яндекса\n- групп ВК\n\nНиже — установка зависимостей, импорт функций и интерактивные формы для ввода URL/токенов.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Установка зависимостей\n",
        "!pip -q install requests beautifulsoup4 lxml ipywidgets pandas shapely pymorphy3 flair folium tqdm\n\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n\n",
        "# Укажите репозиторий в формате \"owner/repo\" при необходимости\n",
        "REPO_SLUG = os.environ.get(\"GITHUB_REPO\", \"Sandrro/digital_identity\")\n",
        "REPO_URL = f\"https://github.com/{REPO_SLUG}\"\n",
        "REPO_DIR = Path(\"/content/digital_identity\")\n\n",
        "if not REPO_DIR.exists():\n",
        "    !git clone --depth 1 {REPO_URL} {REPO_DIR}\n\n",
        "sys.path.insert(0, str(REPO_DIR))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Импорт парсеров\n",
        "import sys\n",
        "sys.path.insert(0, \"/content/digital_identity/parsers\")\n",
        "from vk_group_parser import VKGroupParser\n",
        "from website_parser import parse_websites\n",
        "from yandex_reviews_parser import fetch_yandex_reviews\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Интерактивный запуск\n",
        "import csv\n",
        "from datetime import date, datetime, timezone\n",
        "from pathlib import Path\n",
        "\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "OUTPUT_CSV = Path(\"/content/digital_identity/parsed_texts.csv\")\n",
        "\n",
        "parser_dropdown = widgets.Dropdown(\n",
        "    options=[\n",
        "        (\"Сайты\", \"website\"),\n",
        "        (\"Яндекс отзывы\", \"yandex\"),\n",
        "        (\"ВК группа\", \"vk\"),\n",
        "    ],\n",
        "    description=\"Парсер:\"\n",
        ")\n",
        "url_input = widgets.Text(\n",
        "    value=\"\",\n",
        "    description=\"URL/домен:\",\n",
        "    placeholder=\"https://...\",\n",
        "    layout=widgets.Layout(width=\"80%\"),\n",
        ")\n",
        "token_input = widgets.Password(\n",
        "    value=\"\",\n",
        "    description=\"VK токен:\",\n",
        "    placeholder=\"Требуется только для ВК\",\n",
        ")\n",
        "max_items = widgets.IntSlider(\n",
        "    value=20,\n",
        "    min=1,\n",
        "    max=200,\n",
        "    step=1,\n",
        "    description=\"Лимит:\"\n",
        ")\n",
        "run_button = widgets.Button(description=\"Запустить\")\n",
        "output = widgets.Output()\n",
        "\n",
        "def _normalize_date(value):\n",
        "    if value in (None, \"\"):\n",
        "        return None\n",
        "    if isinstance(value, datetime):\n",
        "        return value.date().isoformat()\n",
        "    if isinstance(value, date):\n",
        "        return value.isoformat()\n",
        "    parsed = pd.to_datetime(value, errors=\"coerce\", utc=True)\n",
        "    if pd.isna(parsed):\n",
        "        return str(value)[:10]\n",
        "    return parsed.date().isoformat()\n",
        "\n",
        "def _format_vk_timestamp(ts):\n",
        "    if ts is None:\n",
        "        return None\n",
        "    return datetime.fromtimestamp(ts, tz=timezone.utc).date().isoformat()\n",
        "\n",
        "def _write_rows(rows):\n",
        "    if not rows:\n",
        "        return\n",
        "    OUTPUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with OUTPUT_CSV.open(\"w\", newline=\"\", encoding=\"utf-8\") as handle:\n",
        "        writer = csv.DictWriter(\n",
        "            handle,\n",
        "            fieldnames=[\"source\", \"url\", \"title\", \"timestamp\", \"text\"],\n",
        "        )\n",
        "        writer.writeheader()\n",
        "        writer.writerows(rows)\n",
        "\n",
        "def run_parser(_):\n",
        "    output.clear_output()\n",
        "    with output:\n",
        "        rows = []\n",
        "        parser = parser_dropdown.value\n",
        "        if parser == \"website\":\n",
        "            df = parse_websites([url_input.value])\n",
        "            for _, row in df.iterrows():\n",
        "                meta = row.get(\"meta\") or {}\n",
        "                rows.append({\n",
        "                    \"source\": row.get(\"source\"),\n",
        "                    \"url\": row.get(\"url\"),\n",
        "                    \"title\": meta.get(\"title\"),\n",
        "                    \"timestamp\": _normalize_date(row.get(\"date\")),\n",
        "                    \"text\": row.get(\"text_clean\") or row.get(\"text_raw\"),\n",
        "                })\n",
        "        elif parser == \"yandex\":\n",
        "            reviews = fetch_yandex_reviews(url_input.value, max_reviews=max_items.value)\n",
        "            for review in reviews:\n",
        "                rows.append({\n",
        "                    \"source\": \"yandex\",\n",
        "                    \"url\": url_input.value,\n",
        "                    \"title\": None,\n",
        "                    \"timestamp\": None,\n",
        "                    \"text\": review.text,\n",
        "                })\n",
        "        else:\n",
        "            if not token_input.value:\n",
        "                raise ValueError(\"Нужен VK токен.\")\n",
        "            vk = VKGroupParser(token_input.value)\n",
        "            for post in vk.iter_posts(url_input.value, total=max_items.value):\n",
        "                rows.append({\n",
        "                    \"source\": \"vk\",\n",
        "                    \"url\": url_input.value,\n",
        "                    \"title\": None,\n",
        "                    \"timestamp\": _format_vk_timestamp(post.date),\n",
        "                    \"text\": post.text,\n",
        "                })\n",
        "        _write_rows(rows)\n",
        "        if rows:\n",
        "            display(pd.DataFrame(rows))\n",
        "\n",
        "run_button.on_click(run_parser)\n",
        "display(parser_dropdown, url_input, token_input, max_items, run_button, output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Геокодирование и визуализация адресов\n\n",
        "Ниже добавлен импорт скрипта геокодера и UI для запуска.\n",
        "В качестве входа используется файл, сохранённый в предыдущей ячейке\n",
        "(`parsed_texts.csv`). Скрипт извлекает топонимы, геокодирует их через Photon,\n",
        "сохраняет результаты в GeoJSON и строит интерактивную карту.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title Геокодер: импорт и запуск с UI\n",
        "import asyncio\n",
        "from pathlib import Path\n\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "from IPython.display import display\n\n",
        "import sys\n",
        "sys.path.insert(0, \"/content/digital_identity/parsers\")\n",
        "from geocoder import geocode_texts, build_geojson, save_geojson, save_map\n\n",
        "DEFAULT_INPUT = Path(\"/content/digital_identity/parsed_texts.csv\")\n\n",
        "file_picker = widgets.Text(\n",
        "    value=str(DEFAULT_INPUT),\n",
        "    description=\"CSV файл:\",\n",
        "    layout=widgets.Layout(width=\"80%\"),\n",
        ")\n",
        "bbox_input = widgets.Text(\n",
        "    value=\"\",\n",
        "    description=\"BBox:\",\n",
        "    placeholder=\"minx,miny,maxx,maxy (необязательно)\",\n",
        "    layout=widgets.Layout(width=\"80%\"),\n",
        ")\n",
        "geojson_output = widgets.Text(\n",
        "    value=\"/content/digital_identity/geocoded_points.geojson\",\n",
        "    description=\"GeoJSON:\",\n",
        "    layout=widgets.Layout(width=\"80%\"),\n",
        ")\n",
        "map_output = widgets.Text(\n",
        "    value=\"/content/digital_identity/geocoded_points.html\",\n",
        "    description=\"HTML карта:\",\n",
        "    layout=widgets.Layout(width=\"80%\"),\n",
        ")\n",
        "run_geocoder = widgets.Button(description=\"Геокодировать\")\n",
        "geo_output = widgets.Output()\n\n",
        "def _load_texts(csv_path: Path) -> list[str]:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    if \"text\" not in df.columns:\n",
        "        raise ValueError(\"CSV должен содержать колонку text\")\n",
        "    return df[\"text\"].fillna(\"\").astype(str).tolist()\n\n",
        "def _run_geocoding(_):\n",
        "    geo_output.clear_output()\n",
        "    with geo_output:\n",
        "        csv_path = Path(file_picker.value).expanduser()\n",
        "        if not csv_path.exists():\n",
        "            raise FileNotFoundError(f\"Файл не найден: {csv_path}\")\n",
        "        texts = _load_texts(csv_path)\n",
        "        bbox = bbox_input.value.strip() or None\n",
        "        results = asyncio.run(geocode_texts(texts, bbox=bbox))\n",
        "        geojson_data = build_geojson(results)\n",
        "        save_geojson(geojson_output.value, geojson_data)\n",
        "        save_map(map_output.value, results)\n",
        "        display({\"geojson\": geojson_output.value, \"map\": map_output.value})\n\n",
        "run_geocoder.on_click(_run_geocoding)\n",
        "display(file_picker, bbox_input, geojson_output, map_output, run_geocoder, geo_output)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "text_parsing_colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}